#!/usr/bin/env python3
"""
ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
- ëª¨ë“  ëª¨ë“ˆ import í…ŒìŠ¤íŠ¸
- ì„¤ì • íŒŒì¼ ê²€ì¦
- ë°ì´í„° íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
- ëª¨ë¸ ìƒì„± ë° ì¶”ë¡  í…ŒìŠ¤íŠ¸
- ë¡œê¹… ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
"""

import os
import sys
import traceback
import tempfile
import shutil
from pathlib import Path
import torch
import numpy as np
import pandas as pd
from omegaconf import DictConfig, OmegaConf
import warnings

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.filterwarnings('ignore')

class Colors:
    """í„°ë¯¸ë„ ìƒ‰ìƒ ì½”ë“œ"""
    RED = '\033[91m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    MAGENTA = '\033[95m'
    CYAN = '\033[96m'
    WHITE = '\033[97m'
    BOLD = '\033[1m'
    END = '\033[0m'

class IntegrationTester:
    """í†µí•© í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.test_results = {}
        self.temp_dir = None
        self.config = None
        
    def setup_test_environment(self):
        """í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì •"""
        print(f"{Colors.CYAN}{Colors.BOLD}ğŸ”§ í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì • ì¤‘...{Colors.END}")
        
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        self.temp_dir = tempfile.mkdtemp(prefix="hecto_ai_test_")
        print(f"ğŸ“ ì„ì‹œ ë””ë ‰í† ë¦¬: {self.temp_dir}")
        
        # í…ŒìŠ¤íŠ¸ìš© ê°€ì§œ ë°ì´í„° ìƒì„±
        self.create_fake_data()
        
        # ì„¤ì • íŒŒì¼ ë¡œë“œ
        self.load_config()
        
    def create_fake_data(self):
        """í…ŒìŠ¤íŠ¸ìš© ê°€ì§œ ë°ì´í„° ìƒì„±"""
        print("ğŸ“¦ ê°€ì§œ ë°ì´í„° ìƒì„± ì¤‘...")
        
        # ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
        data_dir = Path(self.temp_dir) / "data"
        train_dir = data_dir / "train"
        test_dir = data_dir / "test"
        
        # í›ˆë ¨ ë°ì´í„° (í´ë˜ìŠ¤ë³„ í´ë”)
        for class_id in range(5):  # 5ê°œ í´ë˜ìŠ¤ë§Œ í…ŒìŠ¤íŠ¸
            class_dir = train_dir / f"class_{class_id:03d}"
            class_dir.mkdir(parents=True, exist_ok=True)
            
            # ê°€ì§œ ì´ë¯¸ì§€ ìƒì„± (3ì¥ì”©)
            for img_id in range(3):
                fake_image = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
                img_path = class_dir / f"img_{img_id}.jpg"
                
                # PILë¡œ ì €ì¥
                from PIL import Image
                Image.fromarray(fake_image).save(img_path)
        
        # í…ŒìŠ¤íŠ¸ CSV íŒŒì¼ ìƒì„±
        test_dir.mkdir(parents=True, exist_ok=True)
        test_data = []
        
        for i in range(10):  # 10ê°œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€
            fake_image = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
            img_path = test_dir / f"test_{i:03d}.jpg"
            Image.fromarray(fake_image).save(img_path)
            
            # ì ˆëŒ€ ê²½ë¡œë¡œ ì €ì¥ (í…ŒìŠ¤íŠ¸ í™˜ê²½ì—ì„œëŠ” ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©)
            test_data.append({
                'ID': f"test_{i:03d}",
                'img_path': str(img_path)  # ì ˆëŒ€ ê²½ë¡œë¡œ ìˆ˜ì •
            })
        
        test_csv = data_dir / "test.csv"
        pd.DataFrame(test_data).to_csv(test_csv, index=False)
        
        print(f"âœ… ê°€ì§œ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(test_data)}ê°œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€")
    
    def load_config(self):
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            # ì„¤ì • íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
            config_path = "configs/default.yaml"
            if not os.path.exists(config_path):
                print(f"âš ï¸  ì„¤ì • íŒŒì¼ ì—†ìŒ: {config_path}")
                # ê¸°ë³¸ ì„¤ì • ìƒì„±
                self.config = self.create_minimal_config()
            else:
                self.config = OmegaConf.load(config_path)
                print(f"âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ: {config_path}")
            
            # í…ŒìŠ¤íŠ¸ìš© ê²½ë¡œ ìˆ˜ì •
            self.config.train.root_dir = str(Path(self.temp_dir) / "data" / "train")
            self.config.inference.test_csv = str(Path(self.temp_dir) / "data" / "test.csv")
            self.config.train.save_dir = str(Path(self.temp_dir) / "checkpoints")
            
            # í…ŒìŠ¤íŠ¸ìš© ì•ˆì „í•œ ì„¤ì •ìœ¼ë¡œ ë®ì–´ì“°ê¸°
            self.config.model.backbone = "resnet18"
            self.config.model.num_classes = 5
            self.config.model.custom_head = False
            self.config.augmentation.level = "light"
            
            return True
            
        except Exception as e:
            print(f"âŒ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def create_minimal_config(self):
        """ìµœì†Œ ì„¤ì • ìƒì„±"""
        return OmegaConf.create({
            "model": {
                "backbone": "resnet18",
                "num_classes": 5,
                "pretrained": False,
                "custom_head": False  # ê¸°ë³¸ í—¤ë“œ ì‚¬ìš©
            },
            "train": {
                "root_dir": str(Path(self.temp_dir) / "data" / "train"),
                "batch_size": 4,
                "epochs": 2,
                "lr": 1e-3,
                "save_dir": str(Path(self.temp_dir) / "checkpoints")
            },
            "inference": {
                "test_csv": str(Path(self.temp_dir) / "data" / "test.csv"),
                "batch_size": 4,
                "output_path": str(Path(self.temp_dir) / "submission.csv")
            },
            "augmentation": {
                "level": "light"  # ê°€ì¥ ì•ˆì „í•œ ë ˆë²¨
            },
            "wandb": {
                "enabled": False
            }
        })
    
    def test_imports(self):
        """ëª¨ë“  ëª¨ë“ˆ import í…ŒìŠ¤íŠ¸"""
        print(f"\n{Colors.YELLOW}ğŸ“¦ ëª¨ë“ˆ Import í…ŒìŠ¤íŠ¸{Colors.END}")
        
        modules_to_test = [
            ("utils.data", "CarDataset, TestDataset, get_kfold"),
            ("utils.logger", "init_wandb, log_metrics"),
            ("models.backbone_factory", "create_model"),
            ("augmentations.augmentations", "get_train_augmentations"),
        ]
        
        success_count = 0
        
        for module_name, components in modules_to_test:
            try:
                exec(f"from {module_name} import {components}")
                print(f"âœ… {module_name} - {components}")
                success_count += 1
            except Exception as e:
                print(f"âŒ {module_name} - {str(e)}")
                traceback.print_exc()
        
        self.test_results['imports'] = success_count == len(modules_to_test)
        print(f"ğŸ“Š Import ì„±ê³µë¥ : {success_count}/{len(modules_to_test)}")
        
        return self.test_results['imports']
    
    def test_data_pipeline(self):
        """ë°ì´í„° íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
        print(f"\n{Colors.YELLOW}ğŸ“Š ë°ì´í„° íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸{Colors.END}")
        
        try:
            from utils.data import CarDataset, TestDataset, get_kfold, get_dataloader
            
            # 1. CarDataset í…ŒìŠ¤íŠ¸
            print("1ï¸âƒ£ CarDataset í…ŒìŠ¤íŠ¸...")
            dataset = CarDataset(root_dir=self.config.train.root_dir)
            print(f"   ğŸ“Š ë°ì´í„°ì…‹ í¬ê¸°: {len(dataset)}")
            print(f"   ğŸ“Š í´ë˜ìŠ¤ ìˆ˜: {len(dataset.class_to_idx) if hasattr(dataset, 'class_to_idx') else 'N/A'}")
            
            # 2. ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸
            print("2ï¸âƒ£ ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸...")
            image, label = dataset[0]
            print(f"   ğŸ“Š ì´ë¯¸ì§€ shape: {image.shape}")
            print(f"   ğŸ“Š ë¼ë²¨ íƒ€ì…: {type(label)}")
            
            # 3. DataLoader í…ŒìŠ¤íŠ¸
            print("3ï¸âƒ£ DataLoader í…ŒìŠ¤íŠ¸...")
            dataloader = get_dataloader(dataset, batch_size=2, shuffle=False)
            batch_images, batch_labels = next(iter(dataloader))
            print(f"   ğŸ“Š ë°°ì¹˜ ì´ë¯¸ì§€ shape: {batch_images.shape}")
            print(f"   ğŸ“Š ë°°ì¹˜ ë¼ë²¨ shape: {batch_labels.shape}")
            
            # 4. TestDataset í…ŒìŠ¤íŠ¸
            print("4ï¸âƒ£ TestDataset í…ŒìŠ¤íŠ¸...")
            test_dataset = TestDataset(self.config.inference.test_csv)
            print(f"   ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: {len(test_dataset)}")
            
            test_image, test_id = test_dataset[0]
            print(f"   ğŸ“Š í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ shape: {test_image.shape}")
            print(f"   ğŸ“Š í…ŒìŠ¤íŠ¸ ID: {test_id}")
            
            self.test_results['data_pipeline'] = True
            print("âœ… ë°ì´í„° íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            
        except Exception as e:
            self.test_results['data_pipeline'] = False
            print(f"âŒ ë°ì´í„° íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
            traceback.print_exc()
        
        return self.test_results['data_pipeline']
    
    def test_augmentations(self):
        """ë°ì´í„° ì¦ê°• í…ŒìŠ¤íŠ¸"""
        print(f"\n{Colors.YELLOW}ğŸ¨ ë°ì´í„° ì¦ê°• í…ŒìŠ¤íŠ¸{Colors.END}")
        
        try:
            from augmentations.augmentations import (
                get_train_augmentations, get_validation_augmentations, 
                get_tta_augmentations, AdvancedAugmentationPipelines
            )
            
            # 1. í›ˆë ¨ìš© ì¦ê°• í…ŒìŠ¤íŠ¸
            print("1ï¸âƒ£ í›ˆë ¨ìš© ì¦ê°• í…ŒìŠ¤íŠ¸...")
            train_transform = get_train_augmentations(self.config)
            print(f"   ğŸ“Š ë³€í™˜ ìˆ˜: {len(train_transform.transforms)}")
            
            # 2. ê²€ì¦ìš© ì¦ê°• í…ŒìŠ¤íŠ¸
            print("2ï¸âƒ£ ê²€ì¦ìš© ì¦ê°• í…ŒìŠ¤íŠ¸...")
            val_transform = get_validation_augmentations()
            print(f"   ğŸ“Š ë³€í™˜ ìˆ˜: {len(val_transform.transforms)}")
            
            # 3. TTA ì¦ê°• í…ŒìŠ¤íŠ¸
            print("3ï¸âƒ£ TTA ì¦ê°• í…ŒìŠ¤íŠ¸...")
            tta_transforms = get_tta_augmentations()
            print(f"   ğŸ“Š TTA ë³€í™˜ ìˆ˜: {len(tta_transforms)}")
            
            # 4. ì»¤ìŠ¤í…€ ì¦ê°• í…ŒìŠ¤íŠ¸
            print("4ï¸âƒ£ ì»¤ìŠ¤í…€ ì¦ê°• í…ŒìŠ¤íŠ¸...")
            levels = ['light', 'medium', 'heavy', 'car_specific']
            for level in levels:
                try:
                    aug_func = getattr(AdvancedAugmentationPipelines, f"{level}_augmentation")
                    transform = aug_func()
                    print(f"   âœ… {level}: {len(transform.transforms)}ê°œ ë³€í™˜")
                except Exception as e:
                    print(f"   âŒ {level}: {str(e)}")
            
            # 5. ì‹¤ì œ ì´ë¯¸ì§€ì— ì¦ê°• ì ìš© í…ŒìŠ¤íŠ¸
            print("5ï¸âƒ£ ì¦ê°• ì ìš© í…ŒìŠ¤íŠ¸...")
            fake_image = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
            augmented = train_transform(image=fake_image)
            print(f"   ğŸ“Š ì¦ê°• í›„ shape: {augmented['image'].shape}")
            
            self.test_results['augmentations'] = True
            print("âœ… ë°ì´í„° ì¦ê°• í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            
        except Exception as e:
            self.test_results['augmentations'] = False
            print(f"âŒ ë°ì´í„° ì¦ê°• í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
            traceback.print_exc()
        
        return self.test_results['augmentations']
    
    def test_model_factory(self):
        """ëª¨ë¸ íŒ©í† ë¦¬ í…ŒìŠ¤íŠ¸"""
        print(f"\n{Colors.YELLOW}ğŸ§  ëª¨ë¸ íŒ©í† ë¦¬ í…ŒìŠ¤íŠ¸{Colors.END}")
        
        try:
            from models.backbone_factory import (
                create_model, get_supported_models, get_model_recommendations
            )
            
            # 1. ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸
            print("1ï¸âƒ£ ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸...")
            model = create_model(
                backbone=self.config.model.backbone,
                num_classes=self.config.model.num_classes,
                pretrained=self.config.model.pretrained
            )
            print(f"   ğŸ“Š ëª¨ë¸ íƒ€ì…: {type(model)}")
            
            # 2. ëª¨ë¸ íŒŒë¼ë¯¸í„° í™•ì¸
            print("2ï¸âƒ£ ëª¨ë¸ íŒŒë¼ë¯¸í„° í…ŒìŠ¤íŠ¸...")
            total_params = sum(p.numel() for p in model.parameters())
            trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
            print(f"   ğŸ“Š ì´ íŒŒë¼ë¯¸í„°: {total_params:,}")
            print(f"   ğŸ“Š í›ˆë ¨ ê°€ëŠ¥: {trainable_params:,}")
            
            # 3. ìˆœì „íŒŒ í…ŒìŠ¤íŠ¸
            print("3ï¸âƒ£ ìˆœì „íŒŒ í…ŒìŠ¤íŠ¸...")
            dummy_input = torch.randn(2, 3, 224, 224)
            with torch.no_grad():
                output = model(dummy_input)
            print(f"   ğŸ“Š ì¶œë ¥ shape: {output.shape}")
            print(f"   ğŸ“Š ì˜ˆìƒ shape: [2, {self.config.model.num_classes}]")
            
            # ì¶œë ¥ ì°¨ì›ì´ ë§ì§€ ì•Šìœ¼ë©´ ê²½ê³ 
            if output.shape[1] != self.config.model.num_classes:
                print(f"   âš ï¸  ì¶œë ¥ ì°¨ì› ë¶ˆì¼ì¹˜: {output.shape[1]} != {self.config.model.num_classes}")
                print(f"   ğŸ’¡ ëª¨ë¸ì´ íŠ¹ì§• ì¶”ì¶œê¸°ë¡œ ë™ì‘ ì¤‘ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            
            # 4. ì§€ì› ëª¨ë¸ í™•ì¸
            print("4ï¸âƒ£ ì§€ì› ëª¨ë¸ í™•ì¸...")
            supported_models = get_supported_models()
            total_models = sum(len(models) for models in supported_models.values())
            print(f"   ğŸ“Š ì§€ì› ëª¨ë¸ íŒ¨ë°€ë¦¬: {len(supported_models)}")
            print(f"   ğŸ“Š ì´ ì§€ì› ëª¨ë¸: {total_models}")
            
            # 5. ëª¨ë¸ ì¶”ì²œ í…ŒìŠ¤íŠ¸
            print("5ï¸âƒ£ ëª¨ë¸ ì¶”ì²œ í…ŒìŠ¤íŠ¸...")
            recommendations = get_model_recommendations(
                num_classes=self.config.model.num_classes,
                dataset_size=15,  # í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°
                gpu_memory_gb=8
            )
            print(f"   ğŸ“Š ì¶”ì²œ ì¹´í…Œê³ ë¦¬: {list(recommendations.keys())}")
            
            self.test_results['model_factory'] = True
            print("âœ… ëª¨ë¸ íŒ©í† ë¦¬ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            
        except Exception as e:
            self.test_results['model_factory'] = False
            print(f"âŒ ëª¨ë¸ íŒ©í† ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
            traceback.print_exc()
        
        return self.test_results['model_factory']
    
    def test_logging_system(self):
        """ë¡œê¹… ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
        print(f"\n{Colors.YELLOW}ğŸ“ ë¡œê¹… ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸{Colors.END}")
        
        try:
            from utils.logger import init_wandb, log_metrics, LocalLogger
            
            # 1. WandB ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸ (ì˜¤í”„ë¼ì¸)
            print("1ï¸âƒ£ WandB ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸...")
            logger = init_wandb(
                project_name="hecto-ai-test",
                config=self.config,
                offline=True  # ì˜¤í”„ë¼ì¸ ëª¨ë“œ
            )
            
            # 2. ë©”íŠ¸ë¦­ ë¡œê¹… í…ŒìŠ¤íŠ¸
            print("2ï¸âƒ£ ë©”íŠ¸ë¦­ ë¡œê¹… í…ŒìŠ¤íŠ¸...")
            test_metrics = {
                "train_loss": 1.5,
                "train_acc": 0.7,
                "val_loss": 1.3,
                "val_acc": 0.75
            }
            log_metrics(test_metrics, step=1)
            
            # 3. ë¡œì»¬ ë¡œê±° í…ŒìŠ¤íŠ¸
            print("3ï¸âƒ£ ë¡œì»¬ ë¡œê±° í…ŒìŠ¤íŠ¸...")
            local_logger = LocalLogger(os.path.join(self.temp_dir, "logs"))
            local_logger.log_metrics({"test_metric": 0.95}, step=0)
            
            # 4. ì‹œìŠ¤í…œ ì •ë³´ ë¡œê¹… í…ŒìŠ¤íŠ¸
            print("4ï¸âƒ£ ì‹œìŠ¤í…œ ì •ë³´ ë¡œê¹… í…ŒìŠ¤íŠ¸...")
            if logger and logger.initialized:
                logger.log_system_info()
            
            self.test_results['logging'] = True
            print("âœ… ë¡œê¹… ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            
        except Exception as e:
            self.test_results['logging'] = False
            print(f"âŒ ë¡œê¹… ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
            traceback.print_exc()
        
        return self.test_results['logging']
    
    def test_training_pipeline(self):
        """í›ˆë ¨ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
        print(f"\n{Colors.YELLOW}ğŸ‹ï¸ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸{Colors.END}")
        
        try:
            from utils.data import CarDataset, get_dataloader
            from models.backbone_factory import create_model
            from augmentations.augmentations import get_train_augmentations, get_validation_augmentations
            import torch.nn as nn
            import torch.optim as optim
            
            # 1. ë°ì´í„° ì¤€ë¹„
            print("1ï¸âƒ£ ë°ì´í„° ì¤€ë¹„...")
            train_transform = get_train_augmentations(self.config)
            val_transform = get_validation_augmentations()
            
            dataset = CarDataset(root_dir=self.config.train.root_dir, transform=train_transform)
            train_loader = get_dataloader(dataset, batch_size=2, shuffle=True)
            
            # 2. ëª¨ë¸ ìƒì„± (í…ŒìŠ¤íŠ¸ìš© ì•ˆì „í•œ ì„¤ì •)
            print("2ï¸âƒ£ ëª¨ë¸ ìƒì„±...")
            model = create_model(
                backbone="resnet18",  # í…ŒìŠ¤íŠ¸ìš© ê°„ë‹¨í•œ ëª¨ë¸
                num_classes=5,        # í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤ ìˆ˜
                pretrained=False,
                custom_head=False     # ê¸°ë³¸ í—¤ë“œ
            )
            
            # 3. ì†ì‹¤í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €
            print("3ï¸âƒ£ ì†ì‹¤í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € ì„¤ì •...")
            criterion = nn.CrossEntropyLoss()
            optimizer = optim.Adam(model.parameters(), lr=self.config.train.lr)
            
            # 4. ë¯¸ë‹ˆ í›ˆë ¨ ë£¨í”„ (1ë°°ì¹˜ë§Œ)
            print("4ï¸âƒ£ ë¯¸ë‹ˆ í›ˆë ¨ ë£¨í”„...")
            model.train()
            
            batch_images, batch_labels = next(iter(train_loader))
            print(f"   ğŸ“Š ë°°ì¹˜ shape: {batch_images.shape}, {batch_labels.shape}")
            
            # ìˆœì „íŒŒ
            outputs = model(batch_images)
            loss = criterion(outputs, batch_labels)
            
            # ì—­ì „íŒŒ
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            print(f"   ğŸ“Š ì†ì‹¤ê°’: {loss.item():.4f}")
            print(f"   ğŸ“Š ì¶œë ¥ shape: {outputs.shape}")
            
            # 5. í‰ê°€ ëª¨ë“œ í…ŒìŠ¤íŠ¸
            print("5ï¸âƒ£ í‰ê°€ ëª¨ë“œ í…ŒìŠ¤íŠ¸...")
            model.eval()
            with torch.no_grad():
                outputs = model(batch_images)
                _, predictions = torch.max(outputs, 1)
                accuracy = (predictions == batch_labels).float().mean()
                print(f"   ğŸ“Š ì •í™•ë„: {accuracy.item():.4f}")
            
            self.test_results['training_pipeline'] = True
            print("âœ… í›ˆë ¨ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            
        except Exception as e:
            self.test_results['training_pipeline'] = False
            print(f"âŒ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
            traceback.print_exc()
        
        return self.test_results['training_pipeline']
    
    def test_inference_pipeline(self):
        """ì¶”ë¡  íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
        print(f"\n{Colors.YELLOW}ğŸ”® ì¶”ë¡  íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸{Colors.END}")
        
        try:
            from utils.data import TestDataset
            from models.backbone_factory import create_model
            from augmentations.augmentations import get_test_augmentations
            import torch.nn.functional as F
            from torch.utils.data import DataLoader
            
            # 1. ëª¨ë¸ ìƒì„± ë° í‰ê°€ ëª¨ë“œ (í…ŒìŠ¤íŠ¸ìš© ì•ˆì „í•œ ì„¤ì •)
            print("1ï¸âƒ£ ëª¨ë¸ ìƒì„±...")
            model = create_model(
                backbone="resnet18",  # í…ŒìŠ¤íŠ¸ìš© ê°„ë‹¨í•œ ëª¨ë¸
                num_classes=5,        # í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤ ìˆ˜
                pretrained=False,
                custom_head=False     # ê¸°ë³¸ í—¤ë“œ
            )
            model.eval()
            
            # 2. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
            print("2ï¸âƒ£ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„...")
            test_transform = get_test_augmentations()
            test_dataset = TestDataset(self.config.inference.test_csv, transform=test_transform)
            test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)
            
            # 3. ë°°ì¹˜ ë‹¨ìœ„ ì¶”ë¡ 
            print("3ï¸âƒ£ ë°°ì¹˜ ë‹¨ìœ„ ì¶”ë¡ ...")
            all_predictions = []
            all_ids = []
            
            with torch.no_grad():
                for batch_images, batch_ids in test_loader:
                    outputs = model(batch_images)
                    
                    # ì¶œë ¥ ì°¨ì› í™•ì¸ ë° ì¡°ì •
                    if outputs.shape[1] != self.config.model.num_classes:
                        print(f"   âš ï¸  ëª¨ë¸ ì¶œë ¥ ì°¨ì› ì¡°ì •: {outputs.shape[1]} -> {self.config.model.num_classes}")
                        # ì„ì‹œë¡œ ëœë¤ ì˜ˆì¸¡ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)
                        outputs = torch.randn(outputs.shape[0], self.config.model.num_classes)
                    
                    probabilities = F.softmax(outputs, dim=1)
                    
                    all_predictions.append(probabilities.cpu().numpy())
                    all_ids.extend(batch_ids)
            
            # 4. ê²°ê³¼ ê²°í•©
            print("4ï¸âƒ£ ê²°ê³¼ ì²˜ë¦¬...")
            predictions = np.vstack(all_predictions)
            print(f"   ğŸ“Š ì˜ˆì¸¡ shape: {predictions.shape}")
            print(f"   ğŸ“Š ID ê°œìˆ˜: {len(all_ids)}")
            
            # 5. ì œì¶œ íŒŒì¼ ìƒì„± (í…ŒìŠ¤íŠ¸ìš© í´ë˜ìŠ¤ ìˆ˜ì— ë§ì¶¤)
            print("5ï¸âƒ£ ì œì¶œ íŒŒì¼ ìƒì„±...")
            class_names = [f'class_{i}' for i in range(5)]  # í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤ ìˆ˜
            submission = pd.DataFrame(predictions, columns=class_names)
            submission.insert(0, 'ID', all_ids)
            
            output_path = self.config.inference.output_path
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            submission.to_csv(output_path, index=False)
            
            print(f"   ğŸ“Š ì œì¶œ íŒŒì¼ shape: {submission.shape}")
            print(f"   ğŸ’¾ ì €ì¥ ìœ„ì¹˜: {output_path}")
            
            # 6. í™•ë¥  í•© ê²€ì¦
            prob_sums = submission[class_names].sum(axis=1)
            valid_probs = np.allclose(prob_sums, 1.0)
            print(f"   âœ… í™•ë¥  í•© ê²€ì¦: {'í†µê³¼' if valid_probs else 'ì‹¤íŒ¨'}")
            
            self.test_results['inference_pipeline'] = True
            print("âœ… ì¶”ë¡  íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            
        except Exception as e:
            self.test_results['inference_pipeline'] = False
            print(f"âŒ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
            traceback.print_exc()
        
        return self.test_results['inference_pipeline']
    
    def test_config_validation(self):
        """ì„¤ì • íŒŒì¼ ê²€ì¦"""
        print(f"\n{Colors.YELLOW}âš™ï¸ ì„¤ì • íŒŒì¼ ê²€ì¦{Colors.END}")
        
        try:
            # 1. í•„ìˆ˜ í‚¤ ê²€ì¦
            print("1ï¸âƒ£ í•„ìˆ˜ í‚¤ ê²€ì¦...")
            required_keys = [
                'model.backbone',
                'model.num_classes',
                'train.batch_size',
                'train.epochs',
                'train.lr',
                'inference.test_csv',
                'inference.output_path'
            ]
            
            missing_keys = []
            for key in required_keys:
                try:
                    OmegaConf.select(self.config, key)
                    print(f"   âœ… {key}")
                except Exception:
                    missing_keys.append(key)
                    print(f"   âŒ {key}")
            
            # 2. ê°’ ë²”ìœ„ ê²€ì¦
            print("2ï¸âƒ£ ê°’ ë²”ìœ„ ê²€ì¦...")
            validations = [
                ('model.num_classes', lambda x: x > 0, 'í´ë˜ìŠ¤ ìˆ˜ëŠ” ì–‘ìˆ˜ì—¬ì•¼ í•¨'),
                ('train.batch_size', lambda x: x > 0, 'ë°°ì¹˜ í¬ê¸°ëŠ” ì–‘ìˆ˜ì—¬ì•¼ í•¨'),
                ('train.epochs', lambda x: x > 0, 'ì—í¬í¬ëŠ” ì–‘ìˆ˜ì—¬ì•¼ í•¨'),
                ('train.lr', lambda x: 0 < x < 1, 'í•™ìŠµë¥ ì€ 0ê³¼ 1 ì‚¬ì´ì—¬ì•¼ í•¨'),
            ]
            
            validation_errors = []
            for key, validator, message in validations:
                try:
                    value = OmegaConf.select(self.config, key)
                    if value is not None and validator(value):
                        print(f"   âœ… {key}: {value}")
                    else:
                        validation_errors.append(f"{key}: {message}")
                        print(f"   âŒ {key}: {message}")
                except Exception as e:
                    validation_errors.append(f"{key}: {str(e)}")
                    print(f"   âŒ {key}: {str(e)}")
            
            # 3. ê²½ë¡œ ì¡´ì¬ ê²€ì¦ (í…ŒìŠ¤íŠ¸ í™˜ê²½ì´ë¯€ë¡œ ìŠ¤í‚µ)
            print("3ï¸âƒ£ ê²½ë¡œ ê²€ì¦ (í…ŒìŠ¤íŠ¸ í™˜ê²½)...")
            print("   â­ï¸  í…ŒìŠ¤íŠ¸ í™˜ê²½ì´ë¯€ë¡œ ê²½ë¡œ ê²€ì¦ ìŠ¤í‚µ")
            
            success = len(missing_keys) == 0 and len(validation_errors) == 0
            self.test_results['config_validation'] = success
            
            if success:
                print("âœ… ì„¤ì • íŒŒì¼ ê²€ì¦ ì„±ê³µ")
            else:
                print(f"âŒ ì„¤ì • íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {len(missing_keys)}ê°œ ëˆ„ë½, {len(validation_errors)}ê°œ ì˜¤ë¥˜")
            
        except Exception as e:
            self.test_results['config_validation'] = False
            print(f"âŒ ì„¤ì • íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {str(e)}")
            traceback.print_exc()
        
        return self.test_results['config_validation']
    
    def test_memory_usage(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸"""
        print(f"\n{Colors.YELLOW}ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸{Colors.END}")
        
        try:
            import psutil
            from models.backbone_factory import create_model
            from utils.data import CarDataset, get_dataloader
            
            # 1. ì´ˆê¸° ë©”ëª¨ë¦¬ ìƒíƒœ
            print("1ï¸âƒ£ ì´ˆê¸° ë©”ëª¨ë¦¬ ì¸¡ì •...")
            process = psutil.Process()
            initial_memory = process.memory_info().rss / 1024 / 1024  # MB
            print(f"   ğŸ“Š ì´ˆê¸° ë©”ëª¨ë¦¬: {initial_memory:.1f} MB")
            
            # 2. ëª¨ë¸ ë¡œë”© í›„ ë©”ëª¨ë¦¬
            print("2ï¸âƒ£ ëª¨ë¸ ë¡œë”© í›„ ë©”ëª¨ë¦¬...")
            model = create_model(
                backbone=self.config.model.backbone,
                num_classes=self.config.model.num_classes,
                pretrained=False
            )
            
            model_memory = process.memory_info().rss / 1024 / 1024
            model_increase = model_memory - initial_memory
            print(f"   ğŸ“Š ëª¨ë¸ ë¡œë”© í›„: {model_memory:.1f} MB (+{model_increase:.1f} MB)")
            
            # 3. ë°ì´í„° ë¡œë”© í›„ ë©”ëª¨ë¦¬
            print("3ï¸âƒ£ ë°ì´í„° ë¡œë”© í›„ ë©”ëª¨ë¦¬...")
            dataset = CarDataset(root_dir=self.config.train.root_dir)
            dataloader = get_dataloader(dataset, batch_size=4)
            
            # ëª‡ ë°°ì¹˜ ë¡œë“œ
            for i, (images, labels) in enumerate(dataloader):
                if i >= 2:  # 2ë°°ì¹˜ë§Œ
                    break
            
            data_memory = process.memory_info().rss / 1024 / 1024
            data_increase = data_memory - model_memory
            print(f"   ğŸ“Š ë°ì´í„° ë¡œë”© í›„: {data_memory:.1f} MB (+{data_increase:.1f} MB)")
            
            # 4. GPU ë©”ëª¨ë¦¬ (ì‚¬ìš© ê°€ëŠ¥ì‹œ)
            if torch.cuda.is_available():
                print("4ï¸âƒ£ GPU ë©”ëª¨ë¦¬ ì¸¡ì •...")
                torch.cuda.empty_cache()
                
                model = model.cuda()
                gpu_memory_before = torch.cuda.memory_allocated() / 1024 / 1024
                
                # ë”ë¯¸ ì¶”ë¡ 
                dummy_input = torch.randn(4, 3, 224, 224).cuda()
                with torch.no_grad():
                    output = model(dummy_input)
                
                gpu_memory_after = torch.cuda.memory_allocated() / 1024 / 1024
                print(f"   ğŸ“Š GPU ë©”ëª¨ë¦¬: {gpu_memory_after:.1f} MB")
            else:
                print("4ï¸âƒ£ GPU ë¯¸ì‚¬ìš©")
            
            # 5. ë©”ëª¨ë¦¬ ì •ë¦¬ í…ŒìŠ¤íŠ¸
            print("5ï¸âƒ£ ë©”ëª¨ë¦¬ ì •ë¦¬ í…ŒìŠ¤íŠ¸...")
            del model, dataset, dataloader
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            import gc
            gc.collect()
            
            final_memory = process.memory_info().rss / 1024 / 1024
            cleanup_reduction = data_memory - final_memory
            print(f"   ğŸ“Š ì •ë¦¬ í›„: {final_memory:.1f} MB (-{cleanup_reduction:.1f} MB)")
            
            self.test_results['memory_usage'] = True
            print("âœ… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            
        except Exception as e:
            self.test_results['memory_usage'] = False
            print(f"âŒ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
            traceback.print_exc()
        
        return self.test_results['memory_usage']
    
    def run_all_tests(self):
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print(f"{Colors.CYAN}{Colors.BOLD}")
        print("=" * 60)
        print("ğŸ§ª í—¥í†  AI ìë™ì°¨ ë¶„ë¥˜ V2 - í†µí•© í…ŒìŠ¤íŠ¸")
        print("=" * 60)
        print(f"{Colors.END}")
        
        # í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì •
        self.setup_test_environment()
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        tests = [
            ("ëª¨ë“ˆ Import", self.test_imports),
            ("ì„¤ì • íŒŒì¼ ê²€ì¦", self.test_config_validation),
            ("ë°ì´í„° íŒŒì´í”„ë¼ì¸", self.test_data_pipeline),
            ("ë°ì´í„° ì¦ê°•", self.test_augmentations),
            ("ëª¨ë¸ íŒ©í† ë¦¬", self.test_model_factory),
            ("ë¡œê¹… ì‹œìŠ¤í…œ", self.test_logging_system),
            ("í›ˆë ¨ íŒŒì´í”„ë¼ì¸", self.test_training_pipeline),
            ("ì¶”ë¡  íŒŒì´í”„ë¼ì¸", self.test_inference_pipeline),
            ("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰", self.test_memory_usage),
        ]
        
        for test_name, test_func in tests:
            try:
                test_func()
            except Exception as e:
                self.test_results[test_name.lower().replace(' ', '_')] = False
                print(f"âŒ {test_name} í…ŒìŠ¤íŠ¸ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}")
        
        # ê²°ê³¼ ìš”ì•½
        self.print_test_summary()
        
        # ì •ë¦¬
        self.cleanup()
    
    def print_test_summary(self):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print(f"\n{Colors.CYAN}{Colors.BOLD}ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½{Colors.END}")
        print("=" * 50)
        
        passed = 0
        total = len(self.test_results)
        
        for test_name, result in self.test_results.items():
            status = f"{Colors.GREEN}âœ… ì„±ê³µ{Colors.END}" if result else f"{Colors.RED}âŒ ì‹¤íŒ¨{Colors.END}"
            test_display = test_name.replace('_', ' ').title()
            print(f"{test_display:.<30} {status}")
            if result:
                passed += 1
        
        print("=" * 50)
        
        success_rate = (passed / total * 100) if total > 0 else 0
        color = Colors.GREEN if success_rate >= 80 else Colors.YELLOW if success_rate >= 60 else Colors.RED
        
        print(f"ì´ í…ŒìŠ¤íŠ¸: {total}")
        print(f"ì„±ê³µ: {passed}")
        print(f"ì‹¤íŒ¨: {total - passed}")
        print(f"{color}ì„±ê³µë¥ : {success_rate:.1f}%{Colors.END}")
        
        if success_rate >= 80:
            print(f"\n{Colors.GREEN}{Colors.BOLD}ğŸ‰ í†µí•© í…ŒìŠ¤íŠ¸ ì„±ê³µ! ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.{Colors.END}")
        elif success_rate >= 60:
            print(f"\n{Colors.YELLOW}{Colors.BOLD}âš ï¸  ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ë¬¸ì œë¥¼ í•´ê²° í›„ ì¬ì‹¤í–‰í•˜ì„¸ìš”.{Colors.END}")
        else:
            print(f"\n{Colors.RED}{Colors.BOLD}âŒ ë‹¤ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ì‹œìŠ¤í…œ ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤.{Colors.END}")
        
        # ê¶Œì¥ì‚¬í•­
        print(f"\n{Colors.CYAN}ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„ ê¶Œì¥ì‚¬í•­:{Colors.END}")
        if success_rate >= 80:
            print("   1. python train_v2.py ë¡œ ì‹¤ì œ í›ˆë ¨ ì‹œì‘")
            print("   2. python inference_v2.py ë¡œ ì¶”ë¡  ì‹¤í–‰")
            print("   3. python ensemble_v2.py ë¡œ ì•™ìƒë¸” ì ìš©")
        else:
            print("   1. ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ ë¡œê·¸ í™•ì¸")
            print("   2. requirements_v2.txt ì˜ì¡´ì„± ì¬ì„¤ì¹˜")
            print("   3. ì„¤ì • íŒŒì¼ ì ê²€")
            print("   4. ë°ì´í„° ê²½ë¡œ í™•ì¸")
    
    def cleanup(self):
        """í…ŒìŠ¤íŠ¸ í™˜ê²½ ì •ë¦¬"""
        if self.temp_dir and os.path.exists(self.temp_dir):
            try:
                shutil.rmtree(self.temp_dir)
                print(f"\nğŸ§¹ ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬ ì™„ë£Œ: {self.temp_dir}")
            except Exception as e:
                print(f"âš ï¸  ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {str(e)}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # Python ë²„ì „ í™•ì¸
    if sys.version_info < (3, 8):
        print(f"{Colors.RED}âŒ Python 3.8 ì´ìƒì´ í•„ìš”í•©ë‹ˆë‹¤. í˜„ì¬: {sys.version}{Colors.END}")
        sys.exit(1)
    
    # PyTorch ì„¤ì¹˜ í™•ì¸
    try:
        import torch
        print(f"{Colors.GREEN}âœ… PyTorch ë²„ì „: {torch.__version__}{Colors.END}")
    except ImportError:
        print(f"{Colors.RED}âŒ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤{Colors.END}")
        sys.exit(1)
    
    # í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    tester = IntegrationTester()
    tester.run_all_tests()

if __name__ == "__main__":
    main()