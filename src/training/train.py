"""
ê°œì„ ëœ í—¥í†  AI ìë™ì°¨ ë¶„ë¥˜ í›ˆë ¨ íŒŒì´í”„ë¼ì¸
- Hydra ì˜ì¡´ì„± ì œê±°, config.py í†µí•©
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ë°°ì¹˜ ì²˜ë¦¬
- ì•ˆì „í•œ ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œ  
- ì—ëŸ¬ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜
- ê°œì„ ëœ ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§
"""

import os
import sys
import gc
import time
import traceback
from typing import Optional, Dict, List, Tuple
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset, Subset
import pandas as pd
import numpy as np
from tqdm import tqdm

# ë¡œì»¬ ëª¨ë“ˆ import
try:
    from src.utils.config import Config, get_config
    from src.models.backbone_factory import create_model, get_supported_models, get_model_recommendations
    from src.data.data import CarDataset, get_dataloader, get_kfold
    from src.utils.utils import (
        get_memory_usage, clear_memory, safe_model_save, 
        initialize_environment, safe_operation, retry_on_failure
    )
    
    # ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ì •ë¦¬ ë°ì½”ë ˆì´í„° ì •ì˜
    def memory_cleanup_decorator(func):
        """ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ì •ë¦¬ ë°ì½”ë ˆì´í„°"""
        def wrapper(*args, **kwargs):
            try:
                result = func(*args, **kwargs)
                return result
            finally:
                # ì£¼ê¸°ì  ë©”ëª¨ë¦¬ ì •ë¦¬
                if hasattr(torch.cuda, 'empty_cache'):
                    torch.cuda.empty_cache()
                gc.collect()
        return wrapper
    
    # ëˆ„ë½ëœ í•¨ìˆ˜ë“¤ ì •ì˜
    def cleanup_old_checkpoints(save_dir: str, keep_last_n: int = 5):
        """ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì •ë¦¬"""
        try:
            import glob
            checkpoint_files = glob.glob(os.path.join(save_dir, "checkpoint_*.pth"))
            if len(checkpoint_files) > keep_last_n:
                # íŒŒì¼ëª…ì—ì„œ ì—í¬í¬ ë²ˆí˜¸ ì¶”ì¶œí•˜ì—¬ ì •ë ¬
                checkpoint_files.sort(key=lambda x: os.path.getctime(x))
                files_to_remove = checkpoint_files[:-keep_last_n]
                for file_path in files_to_remove:
                    os.remove(file_path)
                    logger.info(f"ğŸ—‘ï¸  ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì‚­ì œ: {os.path.basename(file_path)}")
        except Exception as e:
            logger.warning(f"âš ï¸  ì²´í¬í¬ì¸íŠ¸ ì •ë¦¬ ì‹¤íŒ¨: {str(e)}")
    
    def get_train_val_split(dataset, val_ratio=0.2):
        """ê°„ë‹¨í•œ í›ˆë ¨/ê²€ì¦ ë¶„í• """
        from sklearn.model_selection import train_test_split
        indices = list(range(len(dataset)))
        train_idx, val_idx = train_test_split(indices, test_size=val_ratio, random_state=42)
        
        from torch.utils.data import Subset
        train_subset = Subset(dataset, train_idx)
        val_subset = Subset(dataset, val_idx)
        return train_subset, val_subset
    from utils.logger import init_wandb, log_metrics, finish_wandb
    import logging
    logger = logging.getLogger(__name__)
except ImportError as e:
    import logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    logger.error(f"âŒ ëª¨ë“ˆ Import ì‹¤íŒ¨: {str(e)}")
    logger.error("   í•„ìš”í•œ ëª¨ë“ˆë“¤ì„ í™•ì¸í•˜ì„¸ìš”")
    sys.exit(1)


class TrainingManager:
    """í›ˆë ¨ ê´€ë¦¬ í´ë˜ìŠ¤ - ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì´ê³  ì•ˆì „í•œ í›ˆë ¨"""
    
    def __init__(self, config: Config):
        """
        Args:
            config: ì„¤ì • ê°ì²´
        """
        self.config = config
        self.device = self._setup_device()
        self.model = None
        self.optimizer = None
        self.scheduler = None
        self.criterion = None
        
        # í†µê³„ ì¶”ì 
        self.training_stats = {
            'best_val_acc': 0.0,
            'epochs_without_improvement': 0,
            'total_train_time': 0.0,
            'memory_usage_history': []
        }
        
        # WandB ë¡œê±°
        self.wandb_logger = None
        if config.wandb.enabled:
            self._init_wandb_logger()
        
        logger.info(f"ğŸ‹ï¸ í›ˆë ¨ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"   ğŸ’» ë””ë°”ì´ìŠ¤: {self.device}")
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            logger.info(f"   ğŸ® GPU: {torch.cuda.get_device_name(0)} ({gpu_memory:.1f}GB)")
    
    def _setup_device(self) -> torch.device:
        """ë””ë°”ì´ìŠ¤ ì„¤ì •"""
        hardware_config = getattr(self.config, 'hardware', None)
        device_setting = getattr(hardware_config, 'device', 'auto') if hardware_config else 'auto'
        
        if device_setting == "auto":
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        else:
            device = torch.device(device_setting)
        
        # Mixed precision ì„¤ì •
        mixed_precision = getattr(self.config, 'hardware', None)
        if mixed_precision and getattr(mixed_precision, 'mixed_precision', False) and device.type == "cuda":
            logger.info("âš¡ Mixed Precision (AMP) í™œì„±í™”")
        
        return device
    
    def _init_wandb_logger(self):
        """WandB ë¡œê±° ì´ˆê¸°í™”"""
        try:
            self.wandb_logger = init_wandb(
                project_name=self.config.wandb.project_name,
                config=self.config,
                experiment_name=None,  # ìë™ ìƒì„±
                tags=self.config.wandb.tags,
                offline=self.config.wandb.offline
            )
            logger.info("ğŸ“Š WandB ë¡œê±° ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"âš ï¸  WandB ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            self.config.wandb.enabled = False
    
    @safe_operation("ë°ì´í„°ì…‹ ì¤€ë¹„")
    def prepare_datasets(self) -> Tuple[Dataset, Optional[List]]:
        """ë°ì´í„°ì…‹ ì¤€ë¹„"""
        logger.info("ğŸ“Š ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...")
        # ë°ì´í„°ì…‹ ìƒì„±
        dataset = CarDataset(
            root_dir=self.config.train.root_dir,
            transform=get_train_augmentations(self.config)
        )
        
        logger.info(f"ğŸ“Š ë°ì´í„°ì…‹ ì •ë³´:")
        logger.info(f"   ì´ ì´ë¯¸ì§€: {len(dataset):,}ì¥")
        
        if hasattr(dataset, 'class_to_idx'):
            logger.info(f"   í´ë˜ìŠ¤ ìˆ˜: {len(dataset.class_to_idx)}ê°œ")
            
            # í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸ (ê°„ë‹¨í•œ ë²„ì „)
            logger.info(f"   í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸ ì™„ë£Œ")
        
        # K-Fold ìƒì„± (ì„¤ì •ëœ ê²½ìš°)
        folds = None
        if self.config.train.kfold > 1:
            logger.info("ğŸ”€ K-Fold ìƒì„± ì¤‘...")
            try:
                folds = list(get_kfold(dataset, self.config.train.kfold))
                logger.info(f"ğŸ”€ {self.config.train.kfold}-Fold êµì°¨ê²€ì¦ ì¤€ë¹„ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ K-Fold ìƒì„± ì‹¤íŒ¨: {str(e)}")
                logger.info("   ë‹¨ì¼ í›ˆë ¨/ê²€ì¦ ë¶„í• ë¡œ ì „í™˜")
                folds = None
        
        return dataset, folds
    
    @safe_operation("ëª¨ë¸ ì¤€ë¹„")
    def prepare_model(self) -> bool:
        """ëª¨ë¸ ë° í›ˆë ¨ ì»´í¬ë„ŒíŠ¸ ì¤€ë¹„"""
        
        # ëª¨ë¸ ì¶”ì²œ (ì„¤ì •ëœ ê²½ìš°)
        if hasattr(self.config.model, 'auto_recommend') and self.config.model.auto_recommend:
            logger.info("ğŸ¤– ëª¨ë¸ ìë™ ì¶”ì²œ ì‹¤í–‰...")
            recommendations = get_model_recommendations(
                num_classes=self.config.model.num_classes,
                dataset_size=50000,  # ëŒ€ëµì  ì¶”ì •
                gpu_memory_gb=8.0    # ê¸°ë³¸ê°’
            )
            
            recommended_backbone = recommendations.get('balanced', [self.config.model.backbone])[0]
            logger.info(f"ğŸ’¡ ì¶”ì²œ ëª¨ë¸: {recommended_backbone}")
            
            # ì‚¬ìš©ì ì„ íƒ ì¡´ì¤‘í•˜ë˜ ë¡œê·¸ë§Œ ì¶œë ¥
            if recommended_backbone != self.config.model.backbone:
                logger.info(f"   í˜„ì¬ ì„¤ì •: {self.config.model.backbone}")
                logger.info("   ëª¨ë¸ ë³€ê²½ì„ ì›í•˜ë©´ configì—ì„œ backboneì„ ìˆ˜ì •í•˜ì„¸ìš”")
        
        # ì•ˆì „í•œ ëª¨ë¸ ìƒì„±
        logger.info("ğŸ§  ëª¨ë¸ ìƒì„± ì¤‘...")
        # ëª¨ë¸ ìƒì„± (ê°„ë‹¨í•œ ë²„ì „)
        self.model = create_model(
            backbone=self.config.model.backbone,
            num_classes=self.config.model.num_classes,
            pretrained=self.config.model.pretrained
        )
        self.model = self.model.to(self.device)
        actual_backbone = self.config.model.backbone
        
        # ëª¨ë¸ ì •ë³´ ì¶œë ¥
        total_params = sum(p.numel() for p in self.model.parameters())
        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        
        logger.info(f"ğŸ§  ëª¨ë¸ ì •ë³´:")
        logger.info(f"   ë°±ë³¸: {actual_backbone}")
        logger.info(f"   ì´ íŒŒë¼ë¯¸í„°: {total_params:,}")
        logger.info(f"   í›ˆë ¨ ê°€ëŠ¥: {trainable_params:,}")
        logger.info(f"   ëª¨ë¸ í¬ê¸°: {total_params * 4 / 1024 / 1024:.1f}MB")
        
        # ì†ì‹¤ í•¨ìˆ˜
        self.criterion = nn.CrossEntropyLoss(
            label_smoothing=self.config.train.label_smoothing
        )
        
        # ì˜µí‹°ë§ˆì´ì €
        optimizer_name = getattr(self.config.train, 'optimizer', 'adamw')
        optimizer_cls = {
            'adam': optim.Adam,
            'adamw': optim.AdamW,
            'sgd': optim.SGD
        }.get(optimizer_name.lower(), optim.AdamW)
        
        if optimizer_cls == optim.SGD:
            self.optimizer = optimizer_cls(
                self.model.parameters(),
                lr=self.config.train.lr,
                momentum=0.9,
                weight_decay=self.config.train.weight_decay
            )
        else:
            self.optimizer = optimizer_cls(
                self.model.parameters(),
                lr=self.config.train.lr,
                weight_decay=self.config.train.weight_decay
            )
        
        # ìŠ¤ì¼€ì¤„ëŸ¬
        scheduler_type = getattr(self.config.train, 'scheduler', 'cosine')
        if scheduler_type == 'cosine':
            self.scheduler = optim.lr_scheduler.CosineAnnealingLR(
                self.optimizer, 
                T_max=self.config.train.epochs,
                eta_min=1e-6
            )
        elif scheduler_type == 'step':
            self.scheduler = optim.lr_scheduler.StepLR(
                self.optimizer,
                step_size=self.config.train.epochs // 3,
                gamma=0.1
            )
        else:
            self.scheduler = None
        
        # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ (ì¶”ê°€ëœ ë¶€ë¶„)
        resume_path = self.config.train.resume_path
        self.start_epoch = 0  # ì‹œì‘ ì—í¬í¬ ì´ˆê¸°í™”
        
        if resume_path and os.path.exists(resume_path):
            try:
                logger.info(f"ğŸ”„ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì¤‘: {resume_path}")
                checkpoint = torch.load(resume_path, map_location=self.device, weights_only=False)
                
                # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
                if 'model' in checkpoint:
                    self.model.load_state_dict(checkpoint['model'])
                    logger.info("âœ… ëª¨ë¸ ê°€ì¤‘ì¹˜ ë³µì› ì™„ë£Œ")
                else:
                    logger.warning("âš ï¸ ì²´í¬í¬ì¸íŠ¸ì— ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤")
                
                # ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ ë¡œë“œ
                if 'optimizer' in checkpoint and self.optimizer:
                    self.optimizer.load_state_dict(checkpoint['optimizer'])
                    logger.info("âœ… ì˜µí‹°ë§ˆì´ì € ìƒíƒœ ë³µì› ì™„ë£Œ")
                
                if 'scheduler' in checkpoint and self.scheduler and checkpoint['scheduler']:
                    self.scheduler.load_state_dict(checkpoint['scheduler'])
                    logger.info("âœ… ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ ë³µì› ì™„ë£Œ")
                
                # í›ˆë ¨ ì •ë³´ ë¡œë“œ
                if 'epoch' in checkpoint:
                    self.start_epoch = checkpoint['epoch'] + 1
                    logger.info(f"âœ… ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì™„ë£Œ: ì—í¬í¬ {self.start_epoch}ë¶€í„° í›ˆë ¨ ì¬ê°œ")
                
                # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë³µì›
                metrics = checkpoint.get('metrics', {})
                if metrics:
                    logger.info(f"ğŸ“Š ì´ì „ ì„±ëŠ¥: ì •í™•ë„ {metrics.get('val_acc', 0):.4f}, ì†ì‹¤ {metrics.get('val_loss', 0):.4f}")
            except Exception as e:
                logger.error(f"âŒ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                logger.error(traceback.format_exc())
                logger.info("âš ï¸ ì²˜ìŒë¶€í„° í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        else:
            logger.info("ğŸ†• ìƒˆë¡œìš´ í›ˆë ¨ ì‹œì‘ (ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ)")
        
        logger.info(f"âš™ï¸  í›ˆë ¨ ì„¤ì •:")
        logger.info(f"   ì˜µí‹°ë§ˆì´ì €: {optimizer_name}")
        logger.info(f"   í•™ìŠµë¥ : {self.config.train.lr}")
        logger.info(f"   ìŠ¤ì¼€ì¤„ëŸ¬: {scheduler_type}")
        logger.info(f"   ë ˆì´ë¸” ìŠ¤ë¬´ë”©: {self.config.train.label_smoothing}")
        
        # Mixed Precision Scaler
        self.scaler = None
        hardware_config = getattr(self.config, 'hardware', None)
        if hardware_config and getattr(hardware_config, 'mixed_precision', False) and self.device.type == "cuda":
            self.scaler = torch.cuda.amp.GradScaler()
            logger.info("âš¡ AMP Scaler ì¤€ë¹„ ì™„ë£Œ")
        
        return True
    
    @memory_cleanup_decorator
    def train_one_epoch(self, train_loader: DataLoader, epoch: int) -> Dict[str, float]:
        """í•œ ì—í¬í¬ í›ˆë ¨"""
        self.model.train()
        
        running_loss = 0.0
        running_correct = 0
        running_total = 0
        
        # ì§„í–‰ ë°”
        pbar = tqdm(
            train_loader, 
            desc=f"ğŸƒ ì—í¬í¬ {epoch+1}/{self.config.train.epochs}",
            leave=False
        )
        
        for batch_idx, (images, labels) in enumerate(pbar):
            try:
                # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
                images = images.to(self.device, non_blocking=True)
                
                # MixUp/CutMix ì²˜ë¦¬
                is_mixed = isinstance(labels, tuple)
                if is_mixed:
                    labels_a, labels_b, lam = labels
                    labels_a = labels_a.to(self.device, non_blocking=True)
                    labels_b = labels_b.to(self.device, non_blocking=True)
                else:
                    labels = labels.to(self.device, non_blocking=True)
                
                self.optimizer.zero_grad()
                
                # Mixed Precision ìˆœì „íŒŒ
                if self.scaler:
                    with torch.cuda.amp.autocast():
                        outputs = self.model(images)
                        
                        if is_mixed:
                            loss = lam * self.criterion(outputs, labels_a) + \
                                   (1 - lam) * self.criterion(outputs, labels_b)
                        else:
                            loss = self.criterion(outputs, labels)
                    
                    # Mixed Precision ì—­ì „íŒŒ
                    self.scaler.scale(loss).backward()
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                else:
                    # ì¼ë°˜ ìˆœì „íŒŒ
                    outputs = self.model(images)
                    
                    if is_mixed:
                        loss = lam * self.criterion(outputs, labels_a) + \
                               (1 - lam) * self.criterion(outputs, labels_b)
                    else:
                        loss = self.criterion(outputs, labels)
                    
                    # ì¼ë°˜ ì—­ì „íŒŒ
                    loss.backward()
                    self.optimizer.step()
                
                # í†µê³„ ì—…ë°ì´íŠ¸
                batch_size = images.size(0)
                running_loss += loss.item() * batch_size
                running_total += batch_size
                
                # ì •í™•ë„ ê³„ì‚°
                with torch.no_grad():
                    _, preds = outputs.max(1)
                    if is_mixed:
                        # MixUp/CutMix ì •í™•ë„
                        correct_a = (preds == labels_a).float()
                        correct_b = (preds == labels_b).float()
                        running_correct += (lam * correct_a + (1 - lam) * correct_b).sum().item()
                    else:
                        running_correct += (preds == labels).sum().item()
                
                # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                current_acc = running_correct / running_total if running_total > 0 else 0
                pbar.set_postfix({
                    'Loss': f'{loss.item():.4f}',
                    'Acc': f'{current_acc:.4f}',
                    'LR': f'{self.optimizer.param_groups[0]["lr"]:.6f}'
                })
                
                # ì£¼ê¸°ì  ë©”ëª¨ë¦¬ ì •ë¦¬
                if batch_idx % 100 == 0:
                    del outputs, loss
                    if batch_idx % 500 == 0:  # 500ë°°ì¹˜ë§ˆë‹¤ ê°•ì œ ì •ë¦¬
                        clear_memory(verbose=False)
                
            except Exception as e:
                logger.error(f"âŒ ë°°ì¹˜ {batch_idx} í›ˆë ¨ ì‹¤íŒ¨: {str(e)}")
                # ë©”ëª¨ë¦¬ ì •ë¦¬ í›„ ë‹¤ìŒ ë°°ì¹˜ë¡œ
                clear_memory(verbose=False)
                continue
        
        # ì—í¬í¬ í†µê³„
        epoch_loss = running_loss / running_total if running_total > 0 else 0
        epoch_acc = running_correct / running_total if running_total > 0 else 0
        
        return {
            'train_loss': epoch_loss,
            'train_acc': epoch_acc,
            'samples_processed': running_total
        }
    
    @torch.no_grad()
    def validate_one_epoch(self, val_loader: DataLoader, epoch: int) -> Dict[str, float]:
        """í•œ ì—í¬í¬ ê²€ì¦"""
        self.model.eval()
        
        running_loss = 0.0
        running_correct = 0
        running_total = 0
        
        pbar = tqdm(
            val_loader,
            desc=f"ğŸ” ê²€ì¦ {epoch+1}",
            leave=False
        )
        
        for batch_idx, (images, labels) in enumerate(pbar):
            try:
                images = images.to(self.device, non_blocking=True)
                labels = labels.to(self.device, non_blocking=True)
                
                # Mixed Precision ì¶”ë¡ 
                if self.scaler:
                    with torch.cuda.amp.autocast():
                        outputs = self.model(images)
                        loss = self.criterion(outputs, labels)
                else:
                    outputs = self.model(images)
                    loss = self.criterion(outputs, labels)
                
                # í†µê³„ ì—…ë°ì´íŠ¸
                batch_size = images.size(0)
                running_loss += loss.item() * batch_size
                running_total += batch_size
                
                _, preds = outputs.max(1)
                running_correct += (preds == labels).sum().item()
                
                # ì§„í–‰ ìƒí™©
                current_acc = running_correct / running_total if running_total > 0 else 0
                pbar.set_postfix({
                    'Loss': f'{loss.item():.4f}',
                    'Acc': f'{current_acc:.4f}'
                })
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                if batch_idx % 100 == 0:
                    del outputs, loss
                
            except Exception as e:
                logger.error(f"âŒ ê²€ì¦ ë°°ì¹˜ {batch_idx} ì‹¤íŒ¨: {str(e)}")
                continue
        
        epoch_loss = running_loss / running_total if running_total > 0 else 0
        epoch_acc = running_correct / running_total if running_total > 0 else 0
        
        return {
            'val_loss': epoch_loss,
            'val_acc': epoch_acc,
            'samples_processed': running_total
        }
    
    def save_checkpoint(self, epoch: int, metrics: Dict[str, float], 
                       is_best: bool = False, fold: int = 0):
        """ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        
        checkpoint_info = {
            'epoch': epoch,
            'optimizer': self.optimizer.state_dict(),
            'scheduler': self.scheduler.state_dict() if self.scheduler else None,
            'metrics': metrics,
            'config': self.config,
            'fold': fold
        }
        
        # ì¼ë°˜ ì²´í¬í¬ì¸íŠ¸
        checkpoint_path = os.path.join(
            self.config.train.save_dir, 
            f"checkpoint_fold{fold}_epoch{epoch+1}.pth"
        )
        
        if safe_model_save(self.model, checkpoint_path, checkpoint_info):
            logger.info(f"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: epoch {epoch+1}")
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
        if is_best:
            best_path = os.path.join(
                self.config.train.save_dir,
                f"best_model_fold{fold}.pth"
            )
            if safe_model_save(self.model, best_path, checkpoint_info):
                logger.info(f"ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥: {metrics.get('val_acc', 0):.4f}")
        
        # ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì •ë¦¬
        if (epoch + 1) % 5 == 0:  # 5 ì—í¬í¬ë§ˆë‹¤
            cleanup_old_checkpoints(
                self.config.train.save_dir, 
                keep_last_n=self.config.train.max_checkpoints_keep
            )
    
    def should_early_stop(self, val_acc: float) -> bool:
        """ì¡°ê¸° ì¢…ë£Œ íŒë‹¨"""
        if val_acc > self.training_stats['best_val_acc'] + self.config.train.early_stopping_min_delta:
            self.training_stats['best_val_acc'] = val_acc
            self.training_stats['epochs_without_improvement'] = 0
            return False
        else:
            self.training_stats['epochs_without_improvement'] += 1
            
            if self.training_stats['epochs_without_improvement'] >= self.config.train.early_stopping_patience:
                logger.info(f"ğŸ›‘ ì¡°ê¸° ì¢…ë£Œ: {self.config.train.early_stopping_patience} ì—í¬í¬ ë™ì•ˆ ê°œì„  ì—†ìŒ")
                return True
            
            return False
    
    def train_fold(self, dataset: Dataset, fold_idx: int, 
                   train_indices: List[int], val_indices: List[int]) -> Dict[str, float]:
        """í•œ Fold í›ˆë ¨"""
        
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ“Š Fold {fold_idx+1} ì‹œì‘")
        logger.info(f"   í›ˆë ¨: {len(train_indices):,}ì¥")
        logger.info(f"   ê²€ì¦: {len(val_indices):,}ì¥")
        logger.info(f"{'='*60}")
        
        # Foldë³„ ë°ì´í„° ì¤€ë¹„
        train_subset = Subset(dataset, train_indices)
        val_subset = Subset(dataset, val_indices)
        
        # ì¦ê°• ì„¤ì •
        train_transform = get_train_augmentations(self.config)
        val_transform = get_validation_augmentations()
        
        # Transform ì ìš© (ë°ì´í„°ì…‹ì˜ transform ì†ì„± ìˆ˜ì •)
        train_subset.dataset.transform = train_transform
        val_subset.dataset.transform = val_transform
        
        # ë°ì´í„°ë¡œë” ìƒì„±
        train_loader = get_dataloader(
            train_subset,
            batch_size=self.config.train.batch_size,
            shuffle=True,
            num_workers=self.config.train.num_workers,
            memory_efficient=True,
            memory_limit_mb=16384  # 2048 â†’ 16384 (16GB)
        )
        
        val_loader = get_dataloader(
            val_subset,
            batch_size=self.config.train.batch_size,
            shuffle=False,
            num_workers=self.config.train.num_workers,
            memory_efficient=True,
            memory_limit_mb=8192   # 1024 â†’ 8192 (8GB)
        )
        
        logger.info(f"ğŸ“¦ ë°ì´í„°ë¡œë” ì¤€ë¹„ ì™„ë£Œ:")
        logger.info(f"   í›ˆë ¨ ë°°ì¹˜: {len(train_loader)}")
        logger.info(f"   ê²€ì¦ ë°°ì¹˜: {len(val_loader)}")
        
        # Foldë³„ í†µê³„ ì´ˆê¸°í™”
        fold_best_acc = 0.0
        fold_start_time = time.time()
        
        # ì—í¬í¬ ë£¨í”„ (ì‹œì‘ ì—í¬í¬ë¶€í„°)
        for epoch in range(self.start_epoch, self.config.train.epochs):
            epoch_start_time = time.time()
            
            # ë©”ëª¨ë¦¬ ìƒíƒœ ì²´í¬
            memory_before = get_memory_usage()
            
            # í›ˆë ¨
            train_metrics = self.train_one_epoch(train_loader, epoch)
            
            # ê²€ì¦
            val_metrics = self.validate_one_epoch(val_loader, epoch)
            
            # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
            if self.scheduler:
                self.scheduler.step()
            
            # ë©”íŠ¸ë¦­ ê²°í•©
            epoch_metrics = {**train_metrics, **val_metrics}
            epoch_metrics.update({
                'epoch': epoch + 1,
                'fold': fold_idx,
                'lr': self.optimizer.param_groups[0]['lr']
            })
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì 
            memory_after = get_memory_usage()
            memory_used = memory_after['ram_used'] - memory_before['ram_used']
            epoch_metrics['memory_used_mb'] = memory_used
            
            # ì‹œê°„ ì¸¡ì •
            epoch_time = time.time() - epoch_start_time
            epoch_metrics['epoch_time'] = epoch_time
            
            # ë¡œê¹…
            if self.config.wandb.enabled:
                log_metrics(epoch_metrics, step=epoch)
            
            # ê²°ê³¼ ì¶œë ¥
            total_epochs = self.config.train.epochs - self.start_epoch
            current_epoch = epoch - self.start_epoch + 1
            progress = current_epoch / total_epochs * 100
            
            logger.info(f"\nğŸ“Š ì—í¬í¬ {epoch+1}/{self.config.train.epochs} (ì§„í–‰ë¥ : {progress:.1f}%) ê²°ê³¼:")
            logger.info(f"   ğŸƒ í›ˆë ¨ - Loss: {train_metrics['train_loss']:.4f}, Acc: {train_metrics['train_acc']:.4f}")
            logger.info(f"   ğŸ” ê²€ì¦ - Loss: {val_metrics['val_loss']:.4f}, Acc: {val_metrics['val_acc']:.4f}")
            logger.info(f"   â±ï¸  ì‹œê°„: {epoch_time:.1f}ì´ˆ, ë©”ëª¨ë¦¬: {memory_used:+.1f}MB")
            logger.info(f"   âš™ï¸  í•™ìŠµë¥ : {epoch_metrics['lr']:.6f}")
            
            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            is_best = val_metrics['val_acc'] > fold_best_acc
            if is_best:
                fold_best_acc = val_metrics['val_acc']
            
            self.save_checkpoint(epoch, epoch_metrics, is_best, fold_idx)
            
            # ì¡°ê¸° ì¢…ë£Œ ì²´í¬
            if self.should_early_stop(val_metrics['val_acc']):
                logger.info(f"ğŸ›‘ Fold {fold_idx+1} ì¡°ê¸° ì¢…ë£Œ (Epoch {epoch+1})")
                break
            
            # ì£¼ê¸°ì  ë©”ëª¨ë¦¬ ì •ë¦¬
            if (epoch + 1) % 5 == 0:
                clear_memory(verbose=True)
        
        fold_time = time.time() - fold_start_time
        logger.info(f"\nğŸ Fold {fold_idx+1} ì™„ë£Œ!")
        logger.info(f"   ğŸ† ìµœê³  ê²€ì¦ ì •í™•ë„: {fold_best_acc:.4f}")
        logger.info(f"   â±ï¸  ì´ ì‹œê°„: {fold_time/60:.1f}ë¶„")
        
        return {
            'fold': fold_idx,
            'best_val_acc': fold_best_acc,
            'total_time': fold_time
        }
    
    @safe_operation("ì „ì²´ í›ˆë ¨")
    def train(self):
        """ì „ì²´ í›ˆë ¨ í”„ë¡œì„¸ìŠ¤"""
        logger.info("ğŸš€ í—¥í†  AI ìë™ì°¨ ë¶„ë¥˜ í›ˆë ¨ ì‹œì‘!")
        
        # ë°ì´í„°ì…‹ ì¤€ë¹„
        dataset, folds = self.prepare_datasets()
        if dataset is None:
            logger.error("âŒ ë°ì´í„°ì…‹ ì¤€ë¹„ ì‹¤íŒ¨")
            return
        
        # ëª¨ë¸ ì¤€ë¹„
        if not self.prepare_model():
            logger.error("âŒ ëª¨ë¸ ì¤€ë¹„ ì‹¤íŒ¨")
            return
        
        # í´ë˜ìŠ¤ ë§¤í•‘ ì €ì¥
        if hasattr(dataset, 'class_to_idx'):
            class_mapping_path = os.path.join(self.config.train.save_dir, "class_to_idx.json")
            from utils import safe_json_save
            safe_json_save(dataset.class_to_idx, class_mapping_path)
            logger.info(f"ğŸ’¾ í´ë˜ìŠ¤ ë§¤í•‘ ì €ì¥: {class_mapping_path}")
        
        total_start_time = time.time()
        fold_results = []
        
        if folds:
            # K-Fold êµì°¨ ê²€ì¦
            for fold_idx, (train_indices, val_indices) in enumerate(folds):
                try:
                    fold_result = self.train_fold(dataset, fold_idx, train_indices, val_indices)
                    fold_results.append(fold_result)
                    
                    # Fold ê°„ ë©”ëª¨ë¦¬ ì •ë¦¬
                    clear_memory(verbose=True)
                    
                except Exception as e:
                    logger.error(f"âŒ Fold {fold_idx+1} í›ˆë ¨ ì‹¤íŒ¨: {str(e)}")
                    logger.error(traceback.format_exc())
                    continue
        else:
            # ë‹¨ì¼ í›ˆë ¨/ê²€ì¦ ë¶„í• 
            train_subset, val_subset = get_train_val_split(
                dataset, 
                val_ratio=self.config.train.validation_split
            )
            
            train_indices = train_subset.indices
            val_indices = val_subset.indices
            
            fold_result = self.train_fold(dataset, 0, train_indices, val_indices)
            fold_results.append(fold_result)
        
        # ì „ì²´ ê²°ê³¼ ìš”ì•½
        total_time = time.time() - total_start_time
        
        if fold_results:
            avg_acc = np.mean([r['best_val_acc'] for r in fold_results])
            std_acc = np.std([r['best_val_acc'] for r in fold_results])
            
            logger.info(f"\n{'='*60}")
            logger.info("ğŸ‰ ì „ì²´ í›ˆë ¨ ì™„ë£Œ!")
            logger.info(f"{'='*60}")
            logger.info(f"ğŸ“Š ê²°ê³¼ ìš”ì•½:")
            logger.info(f"   í‰ê·  ê²€ì¦ ì •í™•ë„: {avg_acc:.4f} Â± {std_acc:.4f}")
            logger.info(f"   ì´ í›ˆë ¨ ì‹œê°„: {total_time/60:.1f}ë¶„")
            
            for i, result in enumerate(fold_results):
                logger.info(f"   Fold {i+1}: {result['best_val_acc']:.4f}")
            
            # ìµœì¢… ë©”íŠ¸ë¦­ ë¡œê¹…
            if self.config.wandb.enabled:
                final_metrics = {
                    'final_avg_acc': avg_acc,
                    'final_std_acc': std_acc,
                    'total_training_time': total_time
                }
                log_metrics(final_metrics)
            
            logger.info(f"\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
            logger.info(f"   1. ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë¡œ ì¶”ë¡ : inference_v2.py")
            logger.info(f"   2. ì•™ìƒë¸” ì ìš©: ensemble_v2.py")
            logger.info(f"   3. ëª¨ë¸ ê²½ë¡œ: {self.config.train.save_dir}/best_model_fold*.pth")
        else:
            logger.error("âŒ ëª¨ë“  Fold í›ˆë ¨ ì‹¤íŒ¨")
        
        # ì •ë¦¬
        if self.config.wandb.enabled:
            finish_wandb()


@retry_on_failure(max_retries=2, delay=1.0)
def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    # í™˜ê²½ ì´ˆê¸°í™”
    initialize_environment(seed=42, deterministic=True)
    
    # ì„¤ì • ë¡œë“œ
    try:
        # ëª…ë ¹í–‰ ì¸ìë¡œ ì„¤ì • íƒ€ì… ì§€ì • ê°€ëŠ¥
        config_type = "default"
        if len(sys.argv) > 1:
            config_type = sys.argv[1]
        
        config = get_config(config_type)
        config.print_config()
        
        if not config.validate():
            logger.error("âŒ ì„¤ì • ê²€ì¦ ì‹¤íŒ¨")
            return
        
    except Exception as e:
        logger.error(f"âŒ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        logger.info("   ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤")
        config = get_config("default")
    
    # ì €ì¥ ë””ë ‰í† ë¦¬ í™•ì¸
    if not os.path.exists(config.train.root_dir):
        logger.error(f"âŒ í›ˆë ¨ ë°ì´í„° ë””ë ‰í† ë¦¬ ì—†ìŒ: {config.train.root_dir}")
        logger.error("   ë°ì´í„° ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”")
        return
    
    # í›ˆë ¨ ì‹œì‘
    try:
        trainer = TrainingManager(config)
        trainer.train()
        
    except KeyboardInterrupt:
        logger.info("â¹ï¸  ì‚¬ìš©ìì— ì˜í•´ í›ˆë ¨ ì¤‘ë‹¨")
        clear_memory(verbose=True)
        
    except Exception as e:
        logger.error(f"âŒ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        logger.error(traceback.format_exc())
        clear_memory(verbose=True)
    
    finally:
        # ìµœì¢… ì •ë¦¬
        clear_memory(verbose=True)
        logger.info("ğŸ§¹ í›ˆë ¨ ì„¸ì…˜ ì •ë¦¬ ì™„ë£Œ")


if __name__ == "__main__":
    main()