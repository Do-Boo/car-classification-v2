"""
ì„¤ì • ê´€ë¦¬ ëª¨ë“ˆ - Hydra ì˜ì¡´ì„± ì œê±°
í™˜ê²½ë³€ìˆ˜ì™€ ì½”ë“œ ê¸°ë°˜ ì„¤ì •ìœ¼ë¡œ ì•ˆì •ì„± í™•ë³´
"""

import os
import json
from typing import Optional, Dict, Any, List
from dataclasses import dataclass, field
from pathlib import Path
import torch


@dataclass
class ModelConfig:
    """ëª¨ë¸ ê´€ë ¨ ì„¤ì •"""
    backbone: str = "resnet50"
    num_classes: int = 396
    pretrained: bool = True
    custom_head: bool = False
    dropout: float = 0.2
    
    # fallback ëª¨ë¸ (ë©”ì¸ ëª¨ë¸ ì‹¤íŒ¨ì‹œ)
    fallback_backbone: str = "resnet18"
    
    def __post_init__(self):
        """ì„¤ì • ê²€ì¦"""
        if self.num_classes <= 0:
            raise ValueError(f"num_classes must be positive, got {self.num_classes}")
        if not 0 <= self.dropout <= 1:
            raise ValueError(f"dropout must be in [0,1], got {self.dropout}")


@dataclass
class TrainConfig:
    """í›ˆë ¨ ê´€ë ¨ ì„¤ì •"""
    root_dir: str = "./data/train"
    batch_size: int = 32
    epochs: int = 30
    lr: float = 1e-3
    weight_decay: float = 1e-4
    label_smoothing: float = 0.1
    
    # K-Fold ì„¤ì •
    kfold: int = 5
    
    # ì €ì¥ ë° ì²´í¬í¬ì¸íŠ¸
    save_dir: str = "./checkpoints_v2"
    save_every_n_epochs: int = 5
    max_checkpoints_keep: int = 3
    
    # ë©”ëª¨ë¦¬ ê´€ë¦¬
    num_workers: int = 4
    pin_memory: bool = True
    prefetch_factor: int = 2
    
    # ì¡°ê¸° ì¢…ë£Œ
    early_stopping_patience: int = 10
    early_stopping_min_delta: float = 1e-4
    
    # ì¬ì‹œì‘ ê´€ë ¨
    resume_path: Optional[str] = None
    auto_resume: bool = True
    
    def __post_init__(self):
        """ì„¤ì • ê²€ì¦ ë° ê²½ë¡œ ìƒì„±"""
        if self.batch_size <= 0:
            raise ValueError(f"batch_size must be positive, got {self.batch_size}")
        if self.lr <= 0:
            raise ValueError(f"lr must be positive, got {self.lr}")
        
        # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.save_dir, exist_ok=True)
        os.makedirs(self.root_dir, exist_ok=True)


@dataclass
class AugmentationConfig:
    """ë°ì´í„° ì¦ê°• ì„¤ì •"""
    level: str = "medium"  # light, medium, heavy, car_specific
    
    # ê³ ê¸‰ ì¦ê°• ê¸°ë²•
    use_cutmix: bool = False
    use_mixup: bool = False
    use_gridmask: bool = False
    use_autoaugment: bool = False
    
    # ì¦ê°• íŒŒë¼ë¯¸í„°
    cutmix_alpha: float = 1.0
    mixup_alpha: float = 1.0
    autoaugment_policy: str = "imagenet"
    
    # ê²€ì¦ìš© ì¦ê°• (ì¼ë°˜ì ìœ¼ë¡œ False)
    augment_validation: bool = False
    
    def __post_init__(self):
        """ì„¤ì • ê²€ì¦"""
        valid_levels = ["light", "medium", "heavy", "car_specific"]
        if self.level not in valid_levels:
            raise ValueError(f"level must be one of {valid_levels}, got {self.level}")


@dataclass  
class InferenceConfig:
    """ì¶”ë¡  ê´€ë ¨ ì„¤ì •"""
    test_csv: str = "./data/test.csv"
    output_path: str = "./outputs/submission.csv"
    model_path: Optional[str] = None
    
    # ë°°ì¹˜ ì„¤ì •
    batch_size: int = 64  # ì¶”ë¡ ì‹œ ë” í° ë°°ì¹˜ ì‚¬ìš©
    num_workers: int = 4
    
    # TTA ì„¤ì •
    use_tta: bool = False
    tta_times: int = 5
    
    # ë©”ëª¨ë¦¬ ê´€ë¦¬
    max_memory_gb: float = 8.0
    force_cpu: bool = False
    
    def __post_init__(self):
        """ì„¤ì • ê²€ì¦ ë° ê²½ë¡œ ìƒì„±"""
        if self.batch_size <= 0:
            raise ValueError(f"batch_size must be positive, got {self.batch_size}")
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        output_dir = os.path.dirname(self.output_path)
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)


@dataclass
class EnsembleConfig:
    """ì•™ìƒë¸” ê´€ë ¨ ì„¤ì •"""
    pred_dir: str = "./outputs"
    output_dir: str = "./outputs" 
    output_name: str = "ensemble_submission.csv"
    
    # ì•™ìƒë¸” ë°©ë²•
    ensemble_method: str = "average"  # average, weighted, voting
    weights: Optional[List[float]] = None
    
    # í•„í„°ë§
    min_confidence: float = 0.1
    filter_poor_predictions: bool = True


@dataclass
class WandBConfig:
    """WandB ë¡œê¹… ì„¤ì •"""
    enabled: bool = False  # ê¸°ë³¸ì ìœ¼ë¡œ ë¹„í™œì„±í™”
    project_name: str = "hecto-ai-car-classification"
    entity: Optional[str] = None
    
    # ë¡œê¹… ì„¤ì •
    log_model: bool = True
    log_gradients: bool = False
    log_frequency: int = 100
    
    # ì˜¤í”„ë¼ì¸ ëª¨ë“œ
    offline: bool = False
    
    # WandB ê´€ë ¨ íƒœê·¸
    tags: List[str] = field(default_factory=lambda: ["v2", "car-classification"])


@dataclass
class SystemConfig:
    """ì‹œìŠ¤í…œ ê´€ë ¨ ì„¤ì •"""
    # GPU ì„¤ì •
    device: str = "auto"  # auto, cuda, cpu
    mixed_precision: bool = True
    
    # ë””ë²„ê¹…
    debug: bool = False
    verbose: bool = True
    
    # ì¬í˜„ì„±
    seed: int = 42
    deterministic: bool = True
    
    # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
    profile_memory: bool = False
    profile_time: bool = False


class Config:
    """ì „ì²´ ì„¤ì •ì„ ê´€ë¦¬í•˜ëŠ” ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, config_path: Optional[str] = None):
        """
        ì„¤ì • ì´ˆê¸°í™”
        
        Args:
            config_path: JSON ì„¤ì • íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)
        """
        # ê¸°ë³¸ ì„¤ì • ë¡œë“œ
        self.model = ModelConfig()
        self.train = TrainConfig()
        self.augmentation = AugmentationConfig()
        self.inference = InferenceConfig()
        self.ensemble = EnsembleConfig()
        self.wandb = WandBConfig()
        self.system = SystemConfig()
        
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ
        self._load_from_env()
        
        # JSON íŒŒì¼ì—ì„œ ì„¤ì • ë¡œë“œ (ìˆìœ¼ë©´)
        if config_path and os.path.exists(config_path):
            self.load_from_json(config_path)
            
        # ì‹œìŠ¤í…œ ì„¤ì • ì ìš©
        self._apply_system_config()
    
    def _load_from_env(self):
        """í™˜ê²½ë³€ìˆ˜ì—ì„œ ì£¼ìš” ì„¤ì • ë¡œë“œ"""
        # ëª¨ë¸ ì„¤ì •
        if os.getenv("MODEL_BACKBONE"):
            self.model.backbone = os.getenv("MODEL_BACKBONE")
        if os.getenv("NUM_CLASSES"):
            self.model.num_classes = int(os.getenv("NUM_CLASSES"))
        
        # í›ˆë ¨ ì„¤ì •
        if os.getenv("TRAIN_ROOT_DIR"):
            self.train.root_dir = os.getenv("TRAIN_ROOT_DIR")
        if os.getenv("BATCH_SIZE"):
            self.train.batch_size = int(os.getenv("BATCH_SIZE"))
        if os.getenv("LEARNING_RATE"):
            self.train.lr = float(os.getenv("LEARNING_RATE"))
        if os.getenv("EPOCHS"):
            self.train.epochs = int(os.getenv("EPOCHS"))
        if os.getenv("RESUME_PATH"):  # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ í™˜ê²½ë³€ìˆ˜ ì¶”ê°€
            self.train.resume_path = os.getenv("RESUME_PATH")
            print(f"âœ… ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì„¤ì •: {self.train.resume_path}")
        
        # ì¶”ë¡  ì„¤ì •
        if os.getenv("TEST_CSV"):
            self.inference.test_csv = os.getenv("TEST_CSV")
        if os.getenv("OUTPUT_PATH"):
            self.inference.output_path = os.getenv("OUTPUT_PATH")
        
        # WandB ì„¤ì •
        if os.getenv("WANDB_ENABLED"):
            self.wandb.enabled = os.getenv("WANDB_ENABLED").lower() == "true"
        if os.getenv("WANDB_PROJECT"):
            self.wandb.project_name = os.getenv("WANDB_PROJECT")
        
        # ì‹œìŠ¤í…œ ì„¤ì •
        if os.getenv("DEVICE"):
            self.system.device = os.getenv("DEVICE")
        if os.getenv("DEBUG"):
            self.system.debug = os.getenv("DEBUG").lower() == "true"
    
    def _apply_system_config(self):
        """ì‹œìŠ¤í…œ ì„¤ì • ì ìš©"""
        # ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€
        if self.system.device == "auto":
            if torch.cuda.is_available():
                self.system.device = "cuda"
            else:
                self.system.device = "cpu"
        
        # ì¬í˜„ì„± ì„¤ì •
        if self.system.deterministic:
            torch.manual_seed(self.system.seed)
            if torch.cuda.is_available():
                torch.cuda.manual_seed(self.system.seed)
                torch.cuda.manual_seed_all(self.system.seed)
                torch.backends.cudnn.deterministic = True
                torch.backends.cudnn.benchmark = False
        
        # ë””ë²„ê·¸ ëª¨ë“œ ì„¤ì •
        if self.system.debug:
            self.train.epochs = min(self.train.epochs, 2)
            self.train.batch_size = min(self.train.batch_size, 8)
            self.inference.batch_size = min(self.inference.batch_size, 8)
            print("ğŸ› ë””ë²„ê·¸ ëª¨ë“œ: ì—í¬í¬/ë°°ì¹˜ í¬ê¸° ì¶•ì†Œ")
    
    def load_from_json(self, config_path: str):
        """JSON íŒŒì¼ì—ì„œ ì„¤ì • ë¡œë“œ"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config_dict = json.load(f)
            
            # ê° ì„¹ì…˜ë³„ë¡œ ì„¤ì • ì—…ë°ì´íŠ¸
            if "model" in config_dict:
                self._update_config(self.model, config_dict["model"])
            if "train" in config_dict:
                self._update_config(self.train, config_dict["train"])
            if "augmentation" in config_dict:
                self._update_config(self.augmentation, config_dict["augmentation"])
            if "inference" in config_dict:
                self._update_config(self.inference, config_dict["inference"])
            if "ensemble" in config_dict:
                self._update_config(self.ensemble, config_dict["ensemble"])
            if "wandb" in config_dict:
                self._update_config(self.wandb, config_dict["wandb"])
            if "system" in config_dict:
                self._update_config(self.system, config_dict["system"])
            
            print(f"âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {config_path}")
            
        except Exception as e:
            print(f"âš ï¸  ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {config_path} - {str(e)}")
            print("ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    def _update_config(self, config_obj, config_dict: Dict[str, Any]):
        """ì„¤ì • ê°ì²´ ì—…ë°ì´íŠ¸"""
        for key, value in config_dict.items():
            if hasattr(config_obj, key):
                setattr(config_obj, key, value)
            else:
                print(f"âš ï¸  ì•Œ ìˆ˜ ì—†ëŠ” ì„¤ì •: {key}")
    
    def save_to_json(self, config_path: str):
        """í˜„ì¬ ì„¤ì •ì„ JSON íŒŒì¼ë¡œ ì €ì¥"""
        config_dict = {
            "model": self._dataclass_to_dict(self.model),
            "train": self._dataclass_to_dict(self.train),
            "augmentation": self._dataclass_to_dict(self.augmentation),
            "inference": self._dataclass_to_dict(self.inference),
            "ensemble": self._dataclass_to_dict(self.ensemble),
            "wandb": self._dataclass_to_dict(self.wandb),
            "system": self._dataclass_to_dict(self.system)
        }
        
        os.makedirs(os.path.dirname(config_path), exist_ok=True)
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config_dict, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ ì„¤ì • ì €ì¥ ì™„ë£Œ: {config_path}")
    
    def _dataclass_to_dict(self, obj) -> Dict[str, Any]:
        """dataclassë¥¼ dictë¡œ ë³€í™˜"""
        result = {}
        for field_name in obj.__dataclass_fields__:
            value = getattr(obj, field_name)
            if value is not None:
                result[field_name] = value
        return result
    
    def print_config(self):
        """í˜„ì¬ ì„¤ì • ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ”§ í˜„ì¬ ì„¤ì •")
        print("="*60)
        
        sections = [
            ("ğŸ“± ëª¨ë¸", self.model),
            ("ğŸ‹ï¸ í›ˆë ¨", self.train), 
            ("ğŸ¨ ì¦ê°•", self.augmentation),
            ("ğŸ”® ì¶”ë¡ ", self.inference),
            ("ğŸ”— ì•™ìƒë¸”", self.ensemble),
            ("ğŸ“Š WandB", self.wandb),
            ("ğŸ’» ì‹œìŠ¤í…œ", self.system)
        ]
        
        for section_name, section_obj in sections:
            print(f"\n{section_name}:")
            for field_name in section_obj.__dataclass_fields__:
                value = getattr(section_obj, field_name)
                print(f"   {field_name}: {value}")
        
        print("="*60)
    
    def validate(self) -> bool:
        """ì „ì²´ ì„¤ì • ê²€ì¦"""
        try:
            # ê° ì„¹ì…˜ì˜ __post_init__ í˜¸ì¶œí•´ì„œ ê²€ì¦
            self.model.__post_init__()
            self.train.__post_init__()
            self.augmentation.__post_init__()
            self.inference.__post_init__()
            
            # ì¶”ê°€ êµì°¨ ê²€ì¦
            if self.train.batch_size > 128 and self.system.device == "cpu":
                print("âš ï¸  CPUì—ì„œ í° ë°°ì¹˜ í¬ê¸° ì‚¬ìš© ì¤‘")
            
            if self.wandb.enabled and not self.wandb.project_name:
                raise ValueError("WandB í™œì„±í™” ì‹œ project_name í•„ìš”")
            
            print("âœ… ì„¤ì • ê²€ì¦ ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ ì„¤ì • ê²€ì¦ ì‹¤íŒ¨: {str(e)}")
            return False


def create_default_config() -> Config:
    """ê¸°ë³¸ ì„¤ì • ìƒì„±"""
    return Config()


def create_quick_test_config() -> Config:
    """ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© ì„¤ì • ìƒì„±"""
    config = Config()
    
    # í…ŒìŠ¤íŠ¸ìš© ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ
    config.model.backbone = "resnet18"
    config.train.epochs = 2
    config.train.batch_size = 8
    config.train.kfold = 2
    config.inference.batch_size = 8
    config.system.debug = True
    config.wandb.enabled = False
    
    return config


def create_production_config() -> Config:
    """í”„ë¡œë•ì…˜ìš© ì„¤ì • ìƒì„±"""
    config = Config()
    
    # í”„ë¡œë•ì…˜ ìµœì í™” ì„¤ì •
    config.model.backbone = "efficientnet_b2"
    config.train.epochs = 50
    config.train.batch_size = 32
    config.augmentation.level = "car_specific"
    config.augmentation.use_cutmix = True
    config.inference.use_tta = True
    config.wandb.enabled = True
    
    return config


# í¸ì˜ í•¨ìˆ˜ë“¤
def get_config(config_type: str = "default") -> Config:
    """ì„¤ì • íƒ€ì…ë³„ ì„¤ì • ê°ì²´ ë°˜í™˜"""
    if config_type == "default":
        return create_default_config()
    elif config_type == "test":
        return create_quick_test_config()
    elif config_type == "production":
        return create_production_config()
    else:
        raise ValueError(f"Unknown config type: {config_type}")


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ğŸ§ª ì„¤ì • ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    
    # ê¸°ë³¸ ì„¤ì • í…ŒìŠ¤íŠ¸
    config = create_default_config()
    config.print_config()
    config.validate()
    
    # JSON ì €ì¥/ë¡œë“œ í…ŒìŠ¤íŠ¸
    config.save_to_json("./test_config.json")
    
    # í™˜ê²½ë³€ìˆ˜ í…ŒìŠ¤íŠ¸
    os.environ["MODEL_BACKBONE"] = "resnet34"
    os.environ["BATCH_SIZE"] = "16"
    
    config2 = Config()
    print(f"\ní™˜ê²½ë³€ìˆ˜ ì ìš© ê²°ê³¼:")
    print(f"backbone: {config2.model.backbone}")
    print(f"batch_size: {config2.train.batch_size}")
    
    print("\nâœ… ì„¤ì • ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")