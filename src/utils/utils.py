"""
ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ëª¨ë“ˆ
- ë©”ëª¨ë¦¬ ê´€ë¦¬, ëª¨ë¸ ë¡œë”©, ê²€ì¦, ì—ëŸ¬ ë³µêµ¬ ë“±
- V2 ì½”ë“œì˜ ì¤‘ë³µ ì œê±° ë° ì•ˆì •ì„± í–¥ìƒ
"""

import os
import gc
import json
import time
import shutil
import logging
import psutil
import traceback
from typing import Optional, Dict, Any, List, Tuple, Union
from pathlib import Path
from functools import wraps
from contextlib import contextmanager

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from PIL import Image
import cv2


# ================================
# ë¡œê¹… ì„¤ì •
# ================================

def setup_logging(log_level: str = "INFO", log_file: Optional[str] = None) -> logging.Logger:
    """ë¡œê¹… ì„¤ì •"""
    logger = logging.getLogger("hecto_ai")
    
    # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)
    
    logger.setLevel(getattr(logging, log_level.upper()))
    
    # í¬ë§·í„° ì„¤ì •
    formatter = logging.Formatter(
        '%(asctime)s | %(levelname)-8s | %(name)s | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬ (ì˜µì…˜)
    if log_file:
        os.makedirs(os.path.dirname(log_file), exist_ok=True)
        file_handler = logging.FileHandler(log_file)
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
    
    return logger


# ì „ì—­ ë¡œê±°
logger = setup_logging()


# ================================
# ë©”ëª¨ë¦¬ ê´€ë¦¬
# ================================

def get_memory_usage() -> Dict[str, float]:
    """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ (MB ë‹¨ìœ„)"""
    process = psutil.Process()
    memory_info = {
        'ram_used': process.memory_info().rss / 1024 / 1024,
        'ram_percent': process.memory_percent()
    }
    
    # GPU ë©”ëª¨ë¦¬ (CUDA ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
    if torch.cuda.is_available():
        memory_info.update({
            'gpu_allocated': torch.cuda.memory_allocated() / 1024 / 1024,
            'gpu_reserved': torch.cuda.memory_reserved() / 1024 / 1024,
            'gpu_max_allocated': torch.cuda.max_memory_allocated() / 1024 / 1024
        })
    
    return memory_info


def clear_memory(verbose: bool = True):
    """ë©”ëª¨ë¦¬ ì •ë¦¬"""
    if verbose:
        before = get_memory_usage()
    
    # Python ê°€ë¹„ì§€ ìˆ˜ì§‘
    gc.collect()
    
    # GPU ë©”ëª¨ë¦¬ ì •ë¦¬ (CUDA ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
    if verbose:
        after = get_memory_usage()
        ram_freed = before['ram_used'] - after['ram_used']
        logger.info(f"ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ: RAM {ram_freed:.1f}MB í•´ì œ")
        
        if torch.cuda.is_available():
            gpu_freed = before['gpu_allocated'] - after['gpu_allocated']
            logger.info(f"ğŸ® GPU ë©”ëª¨ë¦¬: {gpu_freed:.1f}MB í•´ì œ")


@contextmanager
def memory_monitor(operation_name: str = "Operation"):
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    before = get_memory_usage()
    start_time = time.time()
    
    try:
        yield
    finally:
        end_time = time.time()
        after = get_memory_usage()
        
        ram_used = after['ram_used'] - before['ram_used']
        duration = end_time - start_time
        
        logger.info(f"ğŸ“Š {operation_name} ì™„ë£Œ:")
        logger.info(f"   â±ï¸  ì†Œìš”ì‹œê°„: {duration:.2f}ì´ˆ")
        logger.info(f"   ğŸ§  RAM ì‚¬ìš©: {ram_used:+.1f}MB")
        
        if torch.cuda.is_available():
            gpu_used = after['gpu_allocated'] - before['gpu_allocated']
            logger.info(f"   ğŸ® GPU ì‚¬ìš©: {gpu_used:+.1f}MB")


def memory_cleanup_decorator(func):
    """ë©”ëª¨ë¦¬ ì •ë¦¬ ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            result = func(*args, **kwargs)
            return result
        finally:
            clear_memory(verbose=False)
    return wrapper


# ================================
# ì•ˆì „í•œ ëª¨ë¸ ê´€ë¦¬
# ================================

def safe_model_load(model_path: str, model_class=None, device: str = "auto", 
                   strict: bool = True, **model_kwargs) -> Optional[nn.Module]:
    """ì•ˆì „í•œ ëª¨ë¸ ë¡œë”© with ì—ëŸ¬ ë³µêµ¬"""
    
    if not os.path.exists(model_path):
        logger.error(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
        return None
    
    # ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€
    if device == "auto":
        device = "cuda" if torch.cuda.is_available() else "cpu"
    
    try:
        logger.info(f"ğŸ“¦ ëª¨ë¸ ë¡œë”© ì‹œì‘: {model_path}")
        
        # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        checkpoint = torch.load(model_path, map_location=device)
        
        # state_dict ì¶”ì¶œ
        if isinstance(checkpoint, dict):
            if 'model' in checkpoint:
                state_dict = checkpoint['model']
            elif 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            else:
                state_dict = checkpoint
        else:
            state_dict = checkpoint
        
        # ëª¨ë¸ ìƒì„± (í´ë˜ìŠ¤ê°€ ì œê³µëœ ê²½ìš°)
        if model_class:
            model = model_class(**model_kwargs)
            
            # state_dict ë¡œë“œ
            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=strict)
            
            if missing_keys:
                logger.warning(f"âš ï¸  ëˆ„ë½ëœ í‚¤: {len(missing_keys)}ê°œ")
            if unexpected_keys:
                logger.warning(f"âš ï¸  ì˜ˆìƒì¹˜ ëª»í•œ í‚¤: {len(unexpected_keys)}ê°œ")
            
            model = model.to(device)
            logger.info(f"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
            return model
        else:
            # state_dictë§Œ ë°˜í™˜
            return state_dict
            
    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
        logger.error(traceback.format_exc())
        return None


def safe_model_save(model: nn.Module, save_path: str, 
                   additional_info: Optional[Dict] = None,
                   create_backup: bool = True) -> bool:
    """ì•ˆì „í•œ ëª¨ë¸ ì €ì¥"""
    
    try:
        # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        
        # ë°±ì—… ìƒì„± (ê¸°ì¡´ íŒŒì¼ì´ ìˆëŠ” ê²½ìš°)
        if create_backup and os.path.exists(save_path):
            backup_path = save_path + ".backup"
            shutil.copy2(save_path, backup_path)
            logger.info(f"ğŸ’¾ ë°±ì—… ìƒì„±: {backup_path}")
        
        # ì €ì¥í•  ì •ë³´ êµ¬ì„±
        save_dict = {
            'model': model.state_dict(),
            'model_class': model.__class__.__name__,
            'save_time': time.time()
        }
        
        # ì¶”ê°€ ì •ë³´ í¬í•¨
        if additional_info:
            save_dict.update(additional_info)
        
        # ì‹¤ì œ ì €ì¥
        torch.save(save_dict, save_path)
        logger.info(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_path}")
        
        # íŒŒì¼ í¬ê¸° í™•ì¸
        file_size = os.path.getsize(save_path) / 1024 / 1024
        logger.info(f"ğŸ“ íŒŒì¼ í¬ê¸°: {file_size:.1f}MB")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        
        # ë°±ì—…ì—ì„œ ë³µêµ¬ ì‹œë„
        if create_backup:
            backup_path = save_path + ".backup"
            if os.path.exists(backup_path):
                shutil.copy2(backup_path, save_path)
                logger.info(f"ğŸ”„ ë°±ì—…ì—ì„œ ë³µêµ¬ ì™„ë£Œ")
        
        return False


def cleanup_old_checkpoints(checkpoint_dir: str, keep_last_n: int = 3):
    """ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì •ë¦¬"""
    
    if not os.path.exists(checkpoint_dir):
        return
    
    # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ë“¤ ì°¾ê¸°
    checkpoint_files = []
    for file in os.listdir(checkpoint_dir):
        if file.endswith(('.pth', '.ckpt', '.pt')):
            file_path = os.path.join(checkpoint_dir, file)
            mtime = os.path.getmtime(file_path)
            checkpoint_files.append((file_path, mtime))
    
    # ìˆ˜ì • ì‹œê°„ ê¸°ì¤€ ì •ë ¬ (ìµœì‹ ìˆœ)
    checkpoint_files.sort(key=lambda x: x[1], reverse=True)
    
    # ì˜¤ë˜ëœ íŒŒì¼ë“¤ ì‚­ì œ
    files_to_delete = checkpoint_files[keep_last_n:]
    for file_path, _ in files_to_delete:
        try:
            os.remove(file_path)
            logger.info(f"ğŸ—‘ï¸  ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì‚­ì œ: {os.path.basename(file_path)}")
        except Exception as e:
            logger.warning(f"âš ï¸  íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {file_path} - {str(e)}")


# ================================
# íŒŒì¼ ì‹œìŠ¤í…œ ìœ í‹¸ë¦¬í‹°
# ================================

def safe_file_read(file_path: str, encoding: str = 'utf-8') -> Optional[str]:
    """ì•ˆì „í•œ íŒŒì¼ ì½ê¸°"""
    try:
        with open(file_path, 'r', encoding=encoding) as f:
            return f.read()
    except Exception as e:
        logger.error(f"âŒ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {file_path} - {str(e)}")
        return None


def safe_json_load(json_path: str) -> Optional[Dict]:
    """ì•ˆì „í•œ JSON ë¡œë“œ"""
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"âŒ JSON ë¡œë“œ ì‹¤íŒ¨: {json_path} - {str(e)}")
        return None


def safe_json_save(data: Dict, json_path: str) -> bool:
    """ì•ˆì „í•œ JSON ì €ì¥"""
    try:
        os.makedirs(os.path.dirname(json_path), exist_ok=True)
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        return True
    except Exception as e:
        logger.error(f"âŒ JSON ì €ì¥ ì‹¤íŒ¨: {json_path} - {str(e)}")
        return False


def ensure_dir_exists(dir_path: str) -> bool:
    """ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸ ë° ìƒì„±"""
    try:
        os.makedirs(dir_path, exist_ok=True)
        return True
    except Exception as e:
        logger.error(f"âŒ ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {dir_path} - {str(e)}")
        return False


def get_dir_size(dir_path: str) -> float:
    """ë””ë ‰í† ë¦¬ í¬ê¸° ê³„ì‚° (MB)"""
    total_size = 0
    for dirpath, dirnames, filenames in os.walk(dir_path):
        for filename in filenames:
            file_path = os.path.join(dirpath, filename)
            try:
                total_size += os.path.getsize(file_path)
            except (OSError, FileNotFoundError):
                continue
    
    return total_size / 1024 / 1024  # MB


def cleanup_temp_files(temp_dir: str = "./temp", max_age_hours: int = 24):
    """ì„ì‹œ íŒŒì¼ ì •ë¦¬"""
    if not os.path.exists(temp_dir):
        return
    
    current_time = time.time()
    max_age_seconds = max_age_hours * 3600
    
    for root, dirs, files in os.walk(temp_dir):
        for file in files:
            file_path = os.path.join(root, file)
            try:
                file_age = current_time - os.path.getmtime(file_path)
                if file_age > max_age_seconds:
                    os.remove(file_path)
                    logger.debug(f"ğŸ§¹ ì„ì‹œ íŒŒì¼ ì‚­ì œ: {file_path}")
            except Exception as e:
                logger.warning(f"âš ï¸  ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {file_path} - {str(e)}")


# ================================
# ì´ë¯¸ì§€ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°
# ================================

def safe_image_load(image_path: str, target_size: Optional[Tuple[int, int]] = None) -> Optional[np.ndarray]:
    """ì•ˆì „í•œ ì´ë¯¸ì§€ ë¡œë”©"""
    try:
        # OpenCVë¡œ ë¡œë“œ
        image = cv2.imread(image_path)
        if image is None:
            logger.warning(f"âš ï¸  OpenCV ë¡œë“œ ì‹¤íŒ¨, PILë¡œ ì¬ì‹œë„: {image_path}")
            
            # PILë¡œ ì¬ì‹œë„
            pil_image = Image.open(image_path).convert('RGB')
            image = np.array(pil_image)
            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        
        # BGR -> RGB ë³€í™˜
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # í¬ê¸° ì¡°ì • (ìš”ì²­ëœ ê²½ìš°)
        if target_size:
            image = cv2.resize(image, target_size)
        
        return image
        
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ ë¡œë”© ì‹¤íŒ¨: {image_path} - {str(e)}")
        
        # ë”ë¯¸ ì´ë¯¸ì§€ ë°˜í™˜
        if target_size:
            return np.zeros((*target_size[::-1], 3), dtype=np.uint8)
        else:
            return np.zeros((224, 224, 3), dtype=np.uint8)


def validate_image_dataset(image_dir: str, min_size: int = 32, 
                          max_aspect_ratio: float = 10.0) -> Dict[str, Any]:
    """ì´ë¯¸ì§€ ë°ì´í„°ì…‹ ê²€ì¦"""
    
    results = {
        'total_images': 0,
        'valid_images': 0,
        'invalid_images': 0,
        'errors': []
    }
    
    if not os.path.exists(image_dir):
        results['errors'].append(f"ë””ë ‰í† ë¦¬ ì—†ìŒ: {image_dir}")
        return results
    
    for root, dirs, files in os.walk(image_dir):
        for file in files:
            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
                results['total_images'] += 1
                image_path = os.path.join(root, file)
                
                try:
                    image = safe_image_load(image_path)
                    if image is not None:
                        h, w = image.shape[:2]
                        
                        # í¬ê¸° ê²€ì¦
                        if min(h, w) < min_size:
                            results['errors'].append(f"í¬ê¸° ë¶€ì¡±: {image_path} ({w}x{h})")
                            results['invalid_images'] += 1
                            continue
                        
                        # ì¢…íš¡ë¹„ ê²€ì¦
                        aspect_ratio = max(h, w) / min(h, w)
                        if aspect_ratio > max_aspect_ratio:
                            results['errors'].append(f"ì¢…íš¡ë¹„ ì´ˆê³¼: {image_path} ({aspect_ratio:.2f})")
                            results['invalid_images'] += 1
                            continue
                        
                        results['valid_images'] += 1
                    else:
                        results['invalid_images'] += 1
                        
                except Exception as e:
                    results['invalid_images'] += 1
                    results['errors'].append(f"ê²€ì¦ ì˜¤ë¥˜: {image_path} - {str(e)}")
    
    return results


# ================================
# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
# ================================

class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.metrics = {}
        self.start_times = {}
    
    def start_timer(self, operation: str):
        """íƒ€ì´ë¨¸ ì‹œì‘"""
        self.start_times[operation] = time.time()
    
    def end_timer(self, operation: str) -> float:
        """íƒ€ì´ë¨¸ ì¢…ë£Œ ë° ì‹œê°„ ë°˜í™˜"""
        if operation in self.start_times:
            duration = time.time() - self.start_times[operation]
            
            if operation not in self.metrics:
                self.metrics[operation] = []
            
            self.metrics[operation].append(duration)
            del self.start_times[operation]
            
            return duration
        else:
            logger.warning(f"âš ï¸  íƒ€ì´ë¨¸ê°€ ì‹œì‘ë˜ì§€ ì•ŠìŒ: {operation}")
            return 0.0
    
    @contextmanager
    def timer(self, operation: str):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € íƒ€ì´ë¨¸"""
        self.start_timer(operation)
        try:
            yield
        finally:
            duration = self.end_timer(operation)
            logger.info(f"â±ï¸  {operation}: {duration:.3f}ì´ˆ")
    
    def get_statistics(self) -> Dict[str, Dict[str, float]]:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        stats = {}
        
        for operation, times in self.metrics.items():
            if times:
                stats[operation] = {
                    'count': len(times),
                    'total': sum(times),
                    'average': np.mean(times),
                    'min': np.min(times),
                    'max': np.max(times),
                    'std': np.std(times)
                }
        
        return stats
    
    def print_statistics(self):
        """ì„±ëŠ¥ í†µê³„ ì¶œë ¥"""
        stats = self.get_statistics()
        
        if not stats:
            print("ğŸ“Š ì„±ëŠ¥ í†µê³„ ì—†ìŒ")
            return
        
        print("\nğŸ“Š ì„±ëŠ¥ í†µê³„:")
        print("-" * 60)
        print(f"{'Operation':<20} {'Count':<8} {'Avg (s)':<10} {'Min (s)':<10} {'Max (s)':<10}")
        print("-" * 60)
        
        for operation, stat in stats.items():
            print(f"{operation:<20} {stat['count']:<8} {stat['average']:<10.3f} "
                  f"{stat['min']:<10.3f} {stat['max']:<10.3f}")
        
        print("-" * 60)


# ì „ì—­ ì„±ëŠ¥ ëª¨ë‹ˆí„°
performance_monitor = PerformanceMonitor()


# ================================
# ì—ëŸ¬ ë³µêµ¬ ìœ í‹¸ë¦¬í‹°
# ================================

def retry_on_failure(max_retries: int = 3, delay: float = 1.0, 
                    backoff_factor: float = 2.0):
    """ì‹¤íŒ¨ì‹œ ì¬ì‹œë„ ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            current_delay = delay
            
            for attempt in range(max_retries + 1):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_retries:
                        logger.error(f"âŒ {func.__name__} ìµœì¢… ì‹¤íŒ¨ after {max_retries} retries: {str(e)}")
                        raise
                    else:
                        logger.warning(f"âš ï¸  {func.__name__} ì‹¤íŒ¨ (attempt {attempt + 1}/{max_retries + 1}): {str(e)}")
                        time.sleep(current_delay)
                        current_delay *= backoff_factor
            
        return wrapper
    return decorator


def safe_operation(operation_name: str = "Operation"):
    """ì•ˆì „í•œ ì‘ì—… ì‹¤í–‰ ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            try:
                logger.info(f"ğŸš€ {operation_name} ì‹œì‘")
                result = func(*args, **kwargs)
                logger.info(f"âœ… {operation_name} ì™„ë£Œ")
                return result
            except Exception as e:
                logger.error(f"âŒ {operation_name} ì‹¤íŒ¨: {str(e)}")
                logger.error(traceback.format_exc())
                return None
        return wrapper
    return decorator


# ================================
# ì‹œìŠ¤í…œ ì •ë³´
# ================================

def get_system_info() -> Dict[str, Any]:
    """ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘"""
    info = {
        'python_version': '.'.join(map(str, __import__('sys').version_info[:3])),
        'platform': __import__('platform').platform(),
        'cpu_count': psutil.cpu_count(),
        'ram_total_gb': psutil.virtual_memory().total / 1024**3,
        'ram_available_gb': psutil.virtual_memory().available / 1024**3,
    }
    
    # PyTorch ì •ë³´
    try:
        info.update({
            'torch_version': torch.__version__,
            'cuda_available': torch.cuda.is_available(),
        })
        
        if torch.cuda.is_available():
            info.update({
                'cuda_version': torch.version.cuda,
                'gpu_count': torch.cuda.device_count(),
                'gpu_name': torch.cuda.get_device_name(0),
                'gpu_memory_gb': torch.cuda.get_device_properties(0).total_memory / 1024**3
            })
    except:
        pass
    
    return info


def print_system_info():
    """ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥"""
    info = get_system_info()
    
    print("\nğŸ’» ì‹œìŠ¤í…œ ì •ë³´:")
    print("-" * 40)
    for key, value in info.items():
        print(f"{key}: {value}")
    print("-" * 40)


# ================================
# ì „ì—­ ì´ˆê¸°í™”
# ================================

def initialize_environment(seed: int = 42, deterministic: bool = True):
    """í™˜ê²½ ì´ˆê¸°í™”"""
    
    # ì¬í˜„ì„± ì„¤ì •
    if deterministic:
        torch.manual_seed(seed)
        np.random.seed(seed)
        
        if torch.cuda.is_available():
            torch.cuda.manual_seed(seed)
            torch.cuda.manual_seed_all(seed)
            torch.backends.cudnn.deterministic = True
            torch.backends.cudnn.benchmark = False
    
    # ë¡œê¹… ì„¤ì •
    logger.info("ğŸ”§ í™˜ê²½ ì´ˆê¸°í™” ì™„ë£Œ")
    
    # ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥
    if logger.isEnabledFor(logging.INFO):
        print_system_info()
    
    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
    cleanup_temp_files()
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    clear_memory(verbose=False)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ğŸ§ª ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    
    # í™˜ê²½ ì´ˆê¸°í™”
    initialize_environment()
    
    # ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸
    with memory_monitor("í…ŒìŠ¤íŠ¸ ì‘ì—…"):
        # ë”ë¯¸ í…ì„œ ìƒì„±
        dummy_tensor = torch.randn(1000, 1000)
        time.sleep(0.1)
    
    # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸
    with performance_monitor.timer("ë”ë¯¸ ì—°ì‚°"):
        time.sleep(0.05)
    
    performance_monitor.print_statistics()
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    clear_memory()
    
    print("âœ… ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")